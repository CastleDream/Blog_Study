{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于这个数据是二分类数据，最后一列是分类， g和b表示，字符串，不是float，所以无法使用np.loadtext来读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('./datasets/ionosphere.data',delimiter=',',header=None,encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分特征和标签\n",
    "X=dataset[:,0:34].astype(float)\n",
    "Y=dataset[:,34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['g', 'b', 'g', 'b'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 按照时间减少lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense,Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder=LabelEncoder()\n",
    "Y=encoder.fit_transform(Y) #数字化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    lr: float >= 0. Learning rate.\n",
    "    momentum: float >= 0. Parameter that accelerates SGD\n",
    "        in the relevant direction and dampens oscillations.\n",
    "    decay: float >= 0. Learning rate decay over each update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 235 samples, validate on 116 samples\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 0s 1ms/step - loss: 0.6856 - acc: 0.5532 - val_loss: 0.6082 - val_acc: 0.9052\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 0s 68us/step - loss: 0.6334 - acc: 0.7319 - val_loss: 0.5437 - val_acc: 0.6810\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 0s 85us/step - loss: 0.5584 - acc: 0.7745 - val_loss: 0.4386 - val_acc: 0.8707\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 0s 77us/step - loss: 0.5108 - acc: 0.8000 - val_loss: 0.6731 - val_acc: 0.6293\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 0s 81us/step - loss: 0.4311 - acc: 0.8298 - val_loss: 0.3148 - val_acc: 0.9483\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 0s 81us/step - loss: 0.3636 - acc: 0.8766 - val_loss: 0.1934 - val_acc: 0.9569\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 0s 72us/step - loss: 0.2952 - acc: 0.8936 - val_loss: 0.4853 - val_acc: 0.7500\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 0s 85us/step - loss: 0.3019 - acc: 0.8894 - val_loss: 0.2273 - val_acc: 0.9569\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 0s 77us/step - loss: 0.2499 - acc: 0.9021 - val_loss: 0.1471 - val_acc: 0.9655\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 0s 94us/step - loss: 0.2134 - acc: 0.9191 - val_loss: 0.2917 - val_acc: 0.9138\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 0s 81us/step - loss: 0.2088 - acc: 0.9191 - val_loss: 0.1947 - val_acc: 0.9569\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 0s 85us/step - loss: 0.1948 - acc: 0.9447 - val_loss: 0.2105 - val_acc: 0.9310\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 0s 89us/step - loss: 0.1685 - acc: 0.9447 - val_loss: 0.1225 - val_acc: 0.9741\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 0s 94us/step - loss: 0.1734 - acc: 0.9404 - val_loss: 0.1192 - val_acc: 0.9741\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 0s 85us/step - loss: 0.1567 - acc: 0.9574 - val_loss: 0.1187 - val_acc: 0.9828\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 0s 89us/step - loss: 0.1589 - acc: 0.9489 - val_loss: 0.1395 - val_acc: 0.9741\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 0s 81us/step - loss: 0.1376 - acc: 0.9617 - val_loss: 0.1193 - val_acc: 0.9741\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 0s 89us/step - loss: 0.1283 - acc: 0.9574 - val_loss: 0.1086 - val_acc: 0.9828\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 0s 85us/step - loss: 0.1210 - acc: 0.9660 - val_loss: 0.1601 - val_acc: 0.9655\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 0s 81us/step - loss: 0.1223 - acc: 0.9617 - val_loss: 0.1314 - val_acc: 0.9741\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 0s 89us/step - loss: 0.1153 - acc: 0.9702 - val_loss: 0.1124 - val_acc: 0.9741\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 0s 94us/step - loss: 0.1071 - acc: 0.9702 - val_loss: 0.1055 - val_acc: 0.9828\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 0s 85us/step - loss: 0.1050 - acc: 0.9745 - val_loss: 0.1620 - val_acc: 0.9569\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 0s 94us/step - loss: 0.1075 - acc: 0.9574 - val_loss: 0.0970 - val_acc: 0.9828\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 0s 89us/step - loss: 0.1024 - acc: 0.9745 - val_loss: 0.0735 - val_acc: 0.9914\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 0s 89us/step - loss: 0.1004 - acc: 0.9702 - val_loss: 0.1658 - val_acc: 0.9569\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 0s 81us/step - loss: 0.1003 - acc: 0.9617 - val_loss: 0.0826 - val_acc: 0.9914\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 0s 94us/step - loss: 0.0900 - acc: 0.9745 - val_loss: 0.0850 - val_acc: 0.9914\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 0s 89us/step - loss: 0.0892 - acc: 0.9787 - val_loss: 0.0955 - val_acc: 0.9828\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 0s 81us/step - loss: 0.0842 - acc: 0.9787 - val_loss: 0.1016 - val_acc: 0.9828\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 0s 77us/step - loss: 0.0826 - acc: 0.9745 - val_loss: 0.0955 - val_acc: 0.9914\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 0s 81us/step - loss: 0.0765 - acc: 0.9787 - val_loss: 0.0774 - val_acc: 0.9914\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 0s 85us/step - loss: 0.0802 - acc: 0.9830 - val_loss: 0.1005 - val_acc: 0.9828\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 0s 81us/step - loss: 0.0731 - acc: 0.9787 - val_loss: 0.0771 - val_acc: 0.9914\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 0s 85us/step - loss: 0.0692 - acc: 0.9787 - val_loss: 0.0999 - val_acc: 0.9914\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 0s 85us/step - loss: 0.0727 - acc: 0.9745 - val_loss: 0.0785 - val_acc: 0.9914\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 0s 81us/step - loss: 0.0792 - acc: 0.9830 - val_loss: 0.0750 - val_acc: 0.9914\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 0s 89us/step - loss: 0.0679 - acc: 0.9830 - val_loss: 0.0809 - val_acc: 0.9914\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 0s 81us/step - loss: 0.0681 - acc: 0.9830 - val_loss: 0.0767 - val_acc: 0.9914\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 0s 85us/step - loss: 0.0642 - acc: 0.9830 - val_loss: 0.0922 - val_acc: 0.9914\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 0s 85us/step - loss: 0.0649 - acc: 0.9830 - val_loss: 0.0903 - val_acc: 0.9914\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 0s 77us/step - loss: 0.0630 - acc: 0.9872 - val_loss: 0.0661 - val_acc: 0.9914\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 0s 85us/step - loss: 0.0619 - acc: 0.9830 - val_loss: 0.0765 - val_acc: 0.9914\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 0s 89us/step - loss: 0.0613 - acc: 0.9830 - val_loss: 0.0725 - val_acc: 0.9914\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 0s 77us/step - loss: 0.0570 - acc: 0.9830 - val_loss: 0.0744 - val_acc: 0.9914\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 0s 98us/step - loss: 0.0572 - acc: 0.9830 - val_loss: 0.0833 - val_acc: 0.9914\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 0s 77us/step - loss: 0.0557 - acc: 0.9830 - val_loss: 0.0699 - val_acc: 0.9914\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 0s 81us/step - loss: 0.0535 - acc: 0.9872 - val_loss: 0.0812 - val_acc: 0.9914\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 0s 85us/step - loss: 0.0535 - acc: 0.9915 - val_loss: 0.0654 - val_acc: 0.9914\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 0s 85us/step - loss: 0.0527 - acc: 0.9872 - val_loss: 0.0682 - val_acc: 0.9914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xd31d64a710>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(34,input_dim=34,activation='relu',kernel_initializer='normal'))\n",
    "model.add(Dense(1,activation='sigmoid',kernel_initializer='normal'))\n",
    "sgd=SGD(lr=0.1,momentum=0.8,decay=0.002,nesterov=False) \n",
    "# 想训练50次，0.1/50=0.002 每次更新 学习率衰减0.002 50次刚好衰减完\n",
    "model.compile(loss='binary_crossentropy',optimizer=sgd,metrics=['accuracy'])\n",
    "model.fit(X,Y,epochs=50,validation_split=0.33,batch_size=28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个准确率很高了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于轮数的学习速度调整"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "还是刚才的网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import LearningRateScheduler\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "    initial_lr=0.1\n",
    "    drop=0.5\n",
    "    epochs_drop=10\n",
    "    lr=initial_lr*math.pow(drop,math.floor((1+epoch)/epochs_drop))\n",
    "    # 初始lr，drop是减速频率，epochs_drop是 降低多少\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    LearningRateScheduler(scheduler)参数说明：\n",
    "\n",
    "    schedule: a function that takes an epoch index as input\n",
    "            (integer, indexed from 0) and current learning rate\n",
    "            and returns a new learning rate as output (float)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 235 samples, validate on 116 samples\n",
      "Epoch 1/50\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.6794 - acc: 0.6000 - val_loss: 0.5940 - val_acc: 0.9310\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 0s 81us/step - loss: 0.6189 - acc: 0.6936 - val_loss: 0.4563 - val_acc: 0.9397\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 0s 102us/step - loss: 0.4951 - acc: 0.8170 - val_loss: 0.4831 - val_acc: 0.8534\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 0s 81us/step - loss: 0.3719 - acc: 0.8681 - val_loss: 0.2948 - val_acc: 0.9138\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 0s 94us/step - loss: 0.2663 - acc: 0.9021 - val_loss: 0.2012 - val_acc: 0.9310\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 0s 102us/step - loss: 0.2183 - acc: 0.9021 - val_loss: 0.1219 - val_acc: 0.9655\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 0s 89us/step - loss: 0.1949 - acc: 0.9149 - val_loss: 0.1061 - val_acc: 0.9741\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 0s 111us/step - loss: 0.1862 - acc: 0.9277 - val_loss: 0.0864 - val_acc: 0.9741\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 0s 94us/step - loss: 0.1626 - acc: 0.9234 - val_loss: 0.2529 - val_acc: 0.8879\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 0s 98us/step - loss: 0.1346 - acc: 0.9447 - val_loss: 0.0856 - val_acc: 0.9828\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 0s 89us/step - loss: 0.1279 - acc: 0.9532 - val_loss: 0.1176 - val_acc: 0.9828\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 0s 123us/step - loss: 0.1106 - acc: 0.9617 - val_loss: 0.0852 - val_acc: 0.9828\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 0s 98us/step - loss: 0.1073 - acc: 0.9660 - val_loss: 0.1198 - val_acc: 0.9741\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 0s 115us/step - loss: 0.0987 - acc: 0.9745 - val_loss: 0.0853 - val_acc: 0.9828\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 0s 98us/step - loss: 0.0909 - acc: 0.9745 - val_loss: 0.0975 - val_acc: 0.9914\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 0s 98us/step - loss: 0.0856 - acc: 0.9745 - val_loss: 0.0780 - val_acc: 0.9914\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 0s 89us/step - loss: 0.0799 - acc: 0.9787 - val_loss: 0.0989 - val_acc: 0.9914\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 0s 98us/step - loss: 0.0776 - acc: 0.9787 - val_loss: 0.0716 - val_acc: 0.9914\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 0s 94us/step - loss: 0.0763 - acc: 0.9830 - val_loss: 0.0923 - val_acc: 0.9914\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 0s 102us/step - loss: 0.0766 - acc: 0.9830 - val_loss: 0.0807 - val_acc: 0.9914\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 0s 98us/step - loss: 0.0676 - acc: 0.9830 - val_loss: 0.0662 - val_acc: 0.9914\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 0s 81us/step - loss: 0.0696 - acc: 0.9830 - val_loss: 0.0714 - val_acc: 0.9914\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 0s 98us/step - loss: 0.0661 - acc: 0.9830 - val_loss: 0.0778 - val_acc: 0.9914\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 0s 94us/step - loss: 0.0663 - acc: 0.9830 - val_loss: 0.0757 - val_acc: 0.9914\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 0s 115us/step - loss: 0.0645 - acc: 0.9830 - val_loss: 0.0721 - val_acc: 0.9914\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 0s 102us/step - loss: 0.0631 - acc: 0.9830 - val_loss: 0.0674 - val_acc: 0.9914\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 0s 98us/step - loss: 0.0616 - acc: 0.9830 - val_loss: 0.0784 - val_acc: 0.9914\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 0s 106us/step - loss: 0.0622 - acc: 0.9830 - val_loss: 0.0717 - val_acc: 0.9914\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 0s 102us/step - loss: 0.0603 - acc: 0.9830 - val_loss: 0.0701 - val_acc: 0.9914\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 0s 85us/step - loss: 0.0592 - acc: 0.9830 - val_loss: 0.0764 - val_acc: 0.9914\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 0s 106us/step - loss: 0.0583 - acc: 0.9830 - val_loss: 0.0692 - val_acc: 0.9914\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 0s 94us/step - loss: 0.0574 - acc: 0.9830 - val_loss: 0.0749 - val_acc: 0.9914\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 0s 89us/step - loss: 0.0577 - acc: 0.9830 - val_loss: 0.0664 - val_acc: 0.9914\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 0s 85us/step - loss: 0.0562 - acc: 0.9830 - val_loss: 0.0693 - val_acc: 0.9914\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 0s 94us/step - loss: 0.0558 - acc: 0.9830 - val_loss: 0.0725 - val_acc: 0.9914\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 0s 94us/step - loss: 0.0554 - acc: 0.9830 - val_loss: 0.0720 - val_acc: 0.9914\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 0s 102us/step - loss: 0.0560 - acc: 0.9830 - val_loss: 0.0662 - val_acc: 0.9914\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 0s 81us/step - loss: 0.0546 - acc: 0.9830 - val_loss: 0.0690 - val_acc: 0.9914\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 0s 98us/step - loss: 0.0545 - acc: 0.9830 - val_loss: 0.0704 - val_acc: 0.9914\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 0s 94us/step - loss: 0.0544 - acc: 0.9830 - val_loss: 0.0638 - val_acc: 0.9914\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 0s 98us/step - loss: 0.0536 - acc: 0.9830 - val_loss: 0.0653 - val_acc: 0.9914\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 0s 98us/step - loss: 0.0532 - acc: 0.9830 - val_loss: 0.0677 - val_acc: 0.9914\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 0s 85us/step - loss: 0.0531 - acc: 0.9830 - val_loss: 0.0706 - val_acc: 0.9914\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 0s 94us/step - loss: 0.0527 - acc: 0.9830 - val_loss: 0.0700 - val_acc: 0.9914\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 0s 102us/step - loss: 0.0527 - acc: 0.9830 - val_loss: 0.0727 - val_acc: 0.9914\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 0s 98us/step - loss: 0.0530 - acc: 0.9830 - val_loss: 0.0752 - val_acc: 0.9914\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 0s 98us/step - loss: 0.0526 - acc: 0.9830 - val_loss: 0.0696 - val_acc: 0.9914\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 0s 89us/step - loss: 0.0517 - acc: 0.9830 - val_loss: 0.0672 - val_acc: 0.9914\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 0s 111us/step - loss: 0.0520 - acc: 0.9830 - val_loss: 0.0645 - val_acc: 0.9914\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 0s 94us/step - loss: 0.0513 - acc: 0.9830 - val_loss: 0.0680 - val_acc: 0.9914\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xd3200ab668>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(34,input_dim=34,activation='relu',kernel_initializer='normal'))\n",
    "model.add(Dense(1,activation='sigmoid',kernel_initializer='normal'))\n",
    "sgd=SGD(lr=0.0,momentum=0.9,decay=0.0,nesterov=False) \n",
    "# 想训练50次，0.1/50=0.002 每次更新 学习率衰减0.002 50次刚好衰减完\n",
    "model.compile(loss='binary_crossentropy',optimizer=sgd,metrics=['accuracy'])\n",
    "\n",
    "lrate=LearningRateScheduler(step_decay)\n",
    "model.fit(X,Y,epochs=50,validation_split=0.33,batch_size=28,callbacks=[lrate])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文中说的不对，这个模型sgd参数改了，而且sgd并不是没有起作用，如果将momentum参数变为0，则效果会变差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
