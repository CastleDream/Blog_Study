{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考 https://www.kesci.com/home/project/5a5e0af01badff1e49557e47"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第11章 声呐返回值分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "data = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data',header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "长知识了，第一次看到用网址作为数据url进行读取的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       9  ...      51      52      53      54      55      56      57      58  \\\n",
       "0  0.2111 ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084  0.0090   \n",
       "1  0.2872 ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049  0.0052   \n",
       "2  0.6194 ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164  0.0095   \n",
       "3  0.1264 ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044  0.0040   \n",
       "4  0.4459 ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048  0.0107   \n",
       "\n",
       "       59  60  \n",
       "0  0.0032   R  \n",
       "1  0.0044   R  \n",
       "2  0.0078   R  \n",
       "3  0.0117   R  \n",
       "4  0.0094   R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 61)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M    111\n",
       "R     97\n",
       "Name: 60, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[:,60].value_counts() #所以这是个二分类问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到数据最后一列是其所属的分类。所有的数据都是连续的（没有缺失值），从0~1，M代表矿石，R代表石头（这是想要挖矿？探测矿藏？）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "D:\\anaconda\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import  np_utils\n",
    "from keras.models import Sequential\n",
    "\n",
    "from sklearn.cross_validation import StratifiedKFold,cross_val_score,KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dataset[:,0:60].astype('float')\n",
    "Y=dataset[:,60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder=LabelEncoder()\n",
    "encoded_Y=encoder.fit_transform(Y)\n",
    "dummy_Y=np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_Y[:4]  #因为是二分类，所以没使用独热码，其实不使用也可以，我的小论文也是二分类，我使用了独热码，可以看看使用和不使用的效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_Y[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_baseline():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(60,input_dim=60,kernel_initializer='normal',activation='relu'))\n",
    "    model.add(Dense(1,kernel_initializer='normal',activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator=KerasClassifier(build_fn=create_baseline,epochs=100,batch_size=5,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:0.80  std:0.07\n"
     ]
    }
   ],
   "source": [
    "EY=encoded_Y\n",
    "kfold=StratifiedKFold(y=EY,n_folds=10,shuffle=True,random_state=seed)\n",
    "results=cross_val_score(estimator,X,EY,cv=kfold)\n",
    "print('mean:%.2f  std:%.2f'%(results.mean(),results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    EY=dummy_Y\n",
    "    # kfold=StratifiedKFold(y=EY,n_folds=10,shuffle=True,random_state=seed)\n",
    "    kfold=KFold(n=len(X),n_folds=10,shuffle=True,random_state=seed)\n",
    "    results=cross_val_score(estimator,X,EY,cv=kfold)\n",
    "    print('mean:%.2f  std:%.2f'%(results.mean(),results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**因为构建网络时，最后一层只有一个输出，所以不同于鸢尾花，使用独热码，模型最后的输出也是3维。<br>\n",
    "你的数据维度要与模型构建保持一致。如果这里模型最后一层是2个输出，那么就需要使用独热码将Y变成二维**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 改进模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 因为这里每一行数据（每一条记录）都有60中特征，为了保证每列分布比较均匀（在进行机器学习模型训练时，最好保证数据的分布一致），使用标准化，让每个数据列的均值为0，方差为0。\n",
    "+ 注意，不能在整个数据集上直接应用标准化，应该只在测试数据进行交叉验证时进行标准化处理，使得标准化成为交叉验证的一环，让模型没有新数据的先验知识，防止模型发散。。。（这几句翻译，其实我觉得并不合理）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    steps : list\n",
    "        List of (name, transform) tuples (implementing fit/transform) that are\n",
    "        chained, in the order in which they are chained, with the last object\n",
    "        an estimator.\n",
    " \n",
    "可放在Pipeline中的步骤可能有：\n",
    "\n",
    "+ 特征标准化是需要的，可作为第一个环节\n",
    "+ 既然是分类器，classifier也是少不了的，自然是最后一个环节\n",
    "+ 中间可加上比如数据降维（PCA）\n",
    "+ ……"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline=Pipeline([('Standardize',StandardScaler()),\n",
    "                  ('mlp',KerasClassifier(build_fn=create_baseline,epochs=100,batch_size=5,verbose=0)),    \n",
    "                  ])\n",
    "kfold=StratifiedKFold(y=encoded_Y,n_folds=10,shuffle=True,random_state=seed)\n",
    "results=cross_val_score(pipeline,X,encoded_Y,cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:84.59%  std:5.20%\n"
     ]
    }
   ],
   "source": [
    "print('mean:%.2f%%  std:%.2f%%'%(results.mean()*100,results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "没有标准化的是 mean:0.82  std:0.08，相比之下，标准化之后提升了还不少。每次运行得到的结果都不一样。。。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 调整模型拓扑和神经元"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 缩小网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_baseline():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(30,input_dim=60,kernel_initializer='normal',activation='relu')) \n",
    "    #在这里试试特征提取，把输入的60维度提取成为30d\n",
    "    model.add(Dense(1,kernel_initializer='normal',activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "pipeline=Pipeline([('Standardize',StandardScaler()),\n",
    "                  ('mlp',KerasClassifier(build_fn=create_baseline,epochs=100,batch_size=5,verbose=0)),    \n",
    "                  ])\n",
    "kfold=StratifiedKFold(y=encoded_Y,n_folds=10,shuffle=True,random_state=seed)\n",
    "results=cross_val_score(pipeline,X,encoded_Y,cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:84.61%  std:5.12%\n"
     ]
    }
   ],
   "source": [
    "print('mean:%.2f%%  std:%.2f%%'%(results.mean()*100,results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "缩小网络降低的不是很多，还可以"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 扩大网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def create_baseline():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(60,input_dim=60,kernel_initializer='normal',activation='relu')) \n",
    "    model.add(Dense(30,kernel_initializer='normal',activation='relu')) #多加一个隐藏层，帮助平稳过渡删选特征\n",
    "    model.add(Dense(1,kernel_initializer='normal',activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "pipeline=Pipeline([('Standardize',StandardScaler()),\n",
    "                  ('mlp',KerasClassifier(build_fn=create_baseline,epochs=100,batch_size=5,verbose=0)),    \n",
    "                  ])\n",
    "kfold=StratifiedKFold(y=encoded_Y,n_folds=10,shuffle=True,random_state=seed)\n",
    "results=cross_val_score(pipeline,X,encoded_Y,cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:85.07%  std:4.54%\n"
     ]
    }
   ],
   "source": [
    "print('mean:%.2f%%  std:%.2f%%'%(results.mean()*100,results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "准确率均值没有很大变化，但是这个网络的std更小，说明这个网络鲁棒性更好了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第16章 使用dropout防止过拟合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先把上面代码全部运行一遍，这样就不用再导入重复的库或者数据了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "与11章相比，16章中compile中optimizer修改成了SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 不使用dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_baseline():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(60,input_dim=60,kernel_initializer='normal',activation='relu')) \n",
    "    model.add(Dense(30,kernel_initializer='normal',activation='relu')) #多加一个隐藏层，帮助平稳过渡删选特征\n",
    "    model.add(Dense(1,kernel_initializer='normal',activation='sigmoid'))\n",
    "    \n",
    "    sgd=SGD(lr=0.01,momentum=0.8,decay=0.0,nesterov=False)\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "pipeline=Pipeline([('Standardize',StandardScaler()),\n",
    "                  ('mlp',KerasClassifier(build_fn=create_baseline,epochs=300,batch_size=16,verbose=0)),    \n",
    "                  ])\n",
    "kfold=StratifiedKFold(y=encoded_Y,n_folds=10,shuffle=True,random_state=seed)\n",
    "results=cross_val_score(pipeline,X,encoded_Y,cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:85.54%  std:4.88%\n"
     ]
    }
   ],
   "source": [
    "print('mean:%.2f%%  std:%.2f%%'%(results.mean()*100,results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://blog.csdn.net/program_developer/article/details/80737724\n",
    "\n",
    "Dropout可以比较有效的缓解过拟合的发生，在一定程度上达到正则化的效果。\n",
    "\n",
    "Dropout可以作为训练深度神经网络的一种trick供选择。在每个训练批次中，通过忽略一半的特征检测器（让一半的隐层节点值为0），可以明显地减少过拟合现象。这种方式可以减少特征检测器（隐层节点）间的相互作用，检测器相互作用是指某些检测器依赖其他检测器才能发挥作用。\n",
    "\n",
    "Dropout说的简单一点就是：我们在前向传播的时候，让某个神经元的激活值以一定的概率p停止工作，这样可以使模型泛化性更强，因为它不会太依赖某些局部的特征。\n",
    "![image](https://img-blog.csdn.net/20180619185225799?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3Byb2dyYW1fZGV2ZWxvcGVy/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "去掉神经元，和文中说的，每五个输入丢掉一个，在实际效果上这样说没错，但是但从含义上来说，是不对的。\n",
    "\n",
    "https://keras.io/layers/core/ 在这个页面搜索dropout 这里的输入不是指狭义上的输入层，是指对每层的输入进行一种小处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对输入层使用dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "from keras.constraints import maxnorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "原论文推荐：\n",
    "\n",
    "对每层的权重加限制，保证模不超过3：，在定义全连接层时使用w_constraint可以做到。学习率加10倍，动量加到0.9\n",
    "\n",
    "https://keras.io/constraints/ 原文代码中使用的w_constraint已经使用kernel_constraint替代了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_baseline():\n",
    "    model=Sequential()\n",
    "    model.add(Dropout(0.2,input_shape=(60,)))\n",
    "    model.add(Dense(60,kernel_initializer='normal',activation='relu',kernel_constraint=maxnorm(3))) \n",
    "    model.add(Dense(30,kernel_initializer='normal',activation='relu',kernel_constraint=maxnorm(3))) #多加一个隐藏层，帮助平稳过渡删选特征\n",
    "    model.add(Dense(1,kernel_initializer='normal',activation='sigmoid'))\n",
    "    \n",
    "    sgd=SGD(lr=0.1,momentum=0.9,decay=0.0,nesterov=False)\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "pipeline=Pipeline([('Standardize',StandardScaler()),\n",
    "                  ('mlp',KerasClassifier(build_fn=create_baseline,epochs=100,batch_size=5,verbose=0)),    \n",
    "                  ])\n",
    "kfold=StratifiedKFold(y=encoded_Y,n_folds=10,shuffle=True,random_state=seed)\n",
    "results=cross_val_score(pipeline,X,encoded_Y,cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:87.95%  std:2.54%\n"
     ]
    }
   ],
   "source": [
    "print('mean:%.2f%%  std:%.2f%%'%(results.mean()*100,results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比不加的 mean:85.54%  std:4.88% 高了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对隐层使用dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_baseline():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(60,input_dim=60,kernel_initializer='normal',activation='relu',kernel_constraint=maxnorm(3))) \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(30,kernel_initializer='normal',activation='relu',kernel_constraint=maxnorm(3))) \n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1,kernel_initializer='normal',activation='sigmoid'))\n",
    "    \n",
    "    sgd=SGD(lr=0.1,momentum=0.9,decay=0.0,nesterov=False)\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "pipeline=Pipeline([('Standardize',StandardScaler()),\n",
    "                  ('mlp',KerasClassifier(build_fn=create_baseline,epochs=100,batch_size=5,verbose=0)),    \n",
    "                  ])\n",
    "kfold=StratifiedKFold(y=encoded_Y,n_folds=10,shuffle=True,random_state=seed)\n",
    "results=cross_val_score(pipeline,X,encoded_Y,cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:85.50%  std:5.49%\n"
     ]
    }
   ],
   "source": [
    "print('mean:%.2f%%  std:%.2f%%'%(results.mean()*100,results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "论调参的重要性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
