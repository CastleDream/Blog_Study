{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">+  19-5-8：使用LSTM网络，不仅仅只使用前馈，使用双向神经网络，因为keras提供了一个非常好的wrapper bidirectional，使得编码非常高效。其实前面的数据处理，数据集构建部分都是一模一样的，我就直接复制了\n",
    "+ 19-5-10：在弄注意力机制的时候，终于注意到了大部分人用的都是theano作为后端，因为np.dot tf.dot theano.dot，tf的dot操作和np的不一样，导致无法使用广播机制还是什么的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考博客：\n",
    "\n",
    "https://richliao.github.io/supervised/classification/2016/12/26/textclassifier-RNN/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_train=pd.read_csv('.../labeledTrainData.tsv',sep='\\t')\n",
    "\n",
    "import re\n",
    "def clean_str(string):\n",
    "    string=re.sub(r\"\\\\\",\"\",string)\n",
    "    string=re.sub(r\"\\'\",\"\",string)\n",
    "    string=re.sub(r'\\\"','',string)\n",
    "    return string.strip().lower()\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "texts=[]\n",
    "for  i in range(data_train.review.shape[0]):\n",
    "    text=BeautifulSoup(data_train.review[i],'lxml')\n",
    "    texts.append(clean_str(text.get_text()))\n",
    "\n",
    "MAX_SENTENCE_LENGTH=1000  #规定每个review的最大长度\n",
    "MAX_NB_WORDS=20000 #整个语料库取词频最高的前2w词\n",
    "EMBEDDING_DIM=300  #用的是glove的100维的词向量原博  我之前是下载的300d的，用自己之前的\n",
    "VALIDATION_SPLIT=0.2 #验证集比例是0.2\n",
    "\n",
    "import keras\n",
    "tokenizer=keras.preprocessing.text.Tokenizer(num_words=MAX_NB_WORDS) #num_words基于词频选择前num_words个词语，和原博客有差异，版本问题\n",
    "tokenizer.fit_on_texts(texts)  #构建了一个分词器，用texts进行训练（单层列表，不能使用reviews）\n",
    "sequences=tokenizer.texts_to_sequences(texts) \n",
    "\n",
    "data=keras.preprocessing.sequence.pad_sequences(sequences,maxlen=MAX_SENTENCE_LENGTH)\n",
    "labels=data_train.sentiment.values\n",
    "\n",
    "indices=np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data=data[indices]\n",
    "labels=labels[indices]\n",
    "nb_validation_samples=int(VALIDATION_SPLIT*data.shape[0])\n",
    "\n",
    "x_train=data[:-nb_validation_samples]\n",
    "y_train=labels[:-nb_validation_samples]\n",
    "x_val=data[-nb_validation_samples:]\n",
    "y_val=labels[-nb_validation_samples:]\n",
    "\n",
    "GLOVE_DIR='../../TheSecond-Paper/word_embedding/en_model.txt'\n",
    "embedding_index={}\n",
    "f=open(GLOVE_DIR)\n",
    "for  line in f:\n",
    "    values=line.split()\n",
    "    word=values[0]\n",
    "    coefs=np.asarray(values[1:],dtype='float64')\n",
    "    embedding_index[word]=coefs\n",
    "f.close()\n",
    "\n",
    "embedding_matrix=np.random.random((len(tokenizer.word_index)+1,EMBEDDING_DIM)) \n",
    "for word,i in tokenizer.word_index.items():   #词 词id\n",
    "    embedding_vector=embedding_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i]=embedding_vector  #词id是从0开始的 词向量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基本模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_input=keras.layers.Input(shape=(MAX_SENTENCE_LENGTH,),dtype='int32')\n",
    "\n",
    "embedded_sequences=keras.layers.Embedding(len(tokenizer.word_index)+1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SENTENCE_LENGTH,\n",
    "                            trainable=False)(sequence_input)\n",
    "l_lstm=keras.layers.Bidirectional(keras.layers.LSTM(100))(embedded_sequences)\n",
    "preds=keras.layers.Dense(1,activation='sigmoid')(l_lstm)\n",
    "model=keras.models.Model(sequence_input,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 1000, 300)         24450600  \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 24,771,601\n",
      "Trainable params: 321,001\n",
      "Non-trainable params: 24,450,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.fit(x_train,y_train,validation_data=(x_val,y_val),epochs=10,batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用LSTM之后特别慢，慢的简直。。。。。慢到我选择放弃，哈哈哈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 注意力机制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 后端采用的问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.4\n",
      "1.12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.4\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "print(keras.__version__)\n",
    "import tensorflow as tf \n",
    "print(tf.__version__)\n",
    "import theano\n",
    "print(theano.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.16.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "theano 1.0.3 与numpy1.16.0版本不兼容，除非升级到theano1.0.4...尴尬，不然报错<br>\n",
    "```python\n",
    "'The following error happened while compiling the node',\"module 'numpy.core.multiarray' has no attribute '_get_ndarray_c_version'\"\n",
    "```\n",
    "Note: Theano 1.0.4 supports NumPy 1.16.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 动态切换后端"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ theano安装：http://deeplearning.net/software/theano/install_windows.html\n",
    "    + 只支持conda安装，Python == 2.7* or ( >= 3.4 and < 3.6 )；NumPy >= 1.9.1 <= 1.12；SciPy >= 0.14 < 0.17.1；    \n",
    "    ``` conda install numpy scipy mkl-service libpython <m2w64-toolchain> <nose> <sphinx> <pydot-ng> <git> ```<br>\n",
    "    其中<>代表是可选的包，所以实际只要执行前面的就可以<br>\n",
    "    考虑到分开安装theano和libgpuarray的复杂性，(需要编译，即便是windows环境下，比较麻烦)决定还是直接安装下面的，自己默认去把libgpuarray当依赖安装吧<br>\n",
    "    ```conda install theano pygpu```  \n",
    "    安装了1.0.3版本，和numpy1.16不兼容，更新至1.0.4   \n",
    "    ```pip install --upgrade theano```\n",
    "    \n",
    "https://stackoverflow.com/questions/42177658/how-to-switch-backend-with-keras-from-tensorflow-to-theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "import os\n",
    "import importlib  #python3 reload模块 reload不再是内建函数 需要显式调用\n",
    "\n",
    "def set_keras_backend(backend):\n",
    "    if K.backend() != backend:\n",
    "        os.environ['KERAS_BACKEND'] = backend\n",
    "        importlib.reload(K)\n",
    "        assert K.backend() == backend\n",
    "\n",
    "set_keras_backend(\"theano\")  #如果后端不是theano 就换成theano\n",
    "import theano\n",
    "# theano.config.floatX= 'float32'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n"
     ]
    }
   ],
   "source": [
    "print(theano.config.floatX)  #然而，很明显，这里已经是32位了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\shanshan/.theanorc.txt'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.expanduser('~/.theanorc.txt') #然而 666的是，找不到。。。卧槽"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        The following code can only strictly run on Theano backend \n",
    "        since tensorflow matrix dot product doesn’t behave the same as np.dot.\n",
    "        I don’t know how to get a 2D tensor \n",
    "        by dot product of 3D tensor of recurrent layer output and 1D tensor of weight.\n",
    "        以下代码只能运行在Theano后端下，因为TensorFlow的矩阵dot操作与np.dot不一样，我不知道如何使得一个3d的RNN网络输出张量和一个1d的权重张量相乘得到一个2d的张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import initializers\n",
    "from keras.layers import Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttLayer(Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        '''\n",
    "        查看源码，https://github.com/tensorflow/tensorflow/blob/r1.13/tensorflow/python/keras/initializers.py\n",
    "        125行 可知 normal这些都是别名  Compatibility aliases 兼容的别名，版本问题真是，呵呵哒\n",
    "        normal = random_normal = RandomNormal\n",
    "        原博这里用的是 initializations.get('normal')\n",
    "        我当前版本应该是 initializers.get('RandomNormal')\n",
    "        '''\n",
    "        self.init=initializers.get('RandomNormal') \n",
    "        super(AttLayer,self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self,input_shape):\n",
    "        assert len(input_shape)==3\n",
    "        self.W=self.init((input_shape[-1],))  #对比之前看到的那个注意力机制的实现，其实这里写的不是很规范\n",
    "        self.trainable_weights=[self.W]\n",
    "        super(AttLayer,self).build(input_shape)\n",
    "        \n",
    "    def call(self,x,mask=None):\n",
    "        '''\n",
    "        https://blog.csdn.net/niuwei22007/article/details/48949869\n",
    "        theano中dimshuffle()函数讲解\n",
    "        '''\n",
    "        eij=K.tanh(K.dot(x,self.W))\n",
    "        ai=K.exp(eij)\n",
    "        weights=ai/K.sum(ai,axis=1).dimshuffle(0,'x')\n",
    "        \n",
    "        weighted_input=x*weights.dimshuffle(0,1,'x')\n",
    "        return weighted_input.sum(axis=1)\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0],input_shape[-1])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bi_GRU with Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_input=keras.layers.Input(shape=(MAX_SENTENCE_LENGTH,),dtype='int32')\n",
    "\n",
    "embedded_sequences=keras.layers.Embedding(len(tokenizer.word_index)+1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SENTENCE_LENGTH,\n",
    "                            trainable=False)(sequence_input)\n",
    "l_gru=keras.layers.Bidirectional(keras.layers.GRU(100,return_sequences=True))(embedded_sequences)\n",
    "l_att=AttLayer()(l_gru)\n",
    "preds=keras.layers.Dense(1,activation='sigmoid')(l_att)\n",
    "model=keras.models.Model(sequence_input,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "('An update must have the same type as the original shared variable (shared_var=training/Adam/variable, shared_var.type=TensorType(float32, scalar), update_val=Elemwise{add,no_inplace}.0, update_val.type=TensorType(float32, vector)).', 'If the difference is related to the broadcast pattern, you can call the tensor.unbroadcast(var, axis_to_unbroadcast[, ...]) function to remove broadcastable dimensions.')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\theano\\compile\\pfunc.py\u001b[0m in \u001b[0;36mrebuild_collect_shared\u001b[1;34m(outputs, inputs, replace, updates, rebuild_strict, copy_inputs_over, no_default_updates)\u001b[0m\n\u001b[0;32m    192\u001b[0m             update_val = store_into.type.filter_variable(update_val,\n\u001b[1;32m--> 193\u001b[1;33m                                                          allow_convert=False)\n\u001b[0m\u001b[0;32m    194\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\theano\\tensor\\type.py\u001b[0m in \u001b[0;36mfilter_variable\u001b[1;34m(self, other, allow_convert)\u001b[0m\n\u001b[0;32m    233\u001b[0m                  \u001b[0mother\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m                  self=self))\n\u001b[0m\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot convert Type TensorType(float32, vector) (of Variable Elemwise{add,no_inplace}.0) into Type TensorType(float32, scalar). You can try to manually convert Elemwise{add,no_inplace}.0 into a TensorType(float32, scalar).",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-3a1ad87f8db9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1008\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1010\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1011\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_make_train_function\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    517\u001b[0m                     \u001b[0mupdates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m                     \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train_function'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m                     **self._function_kwargs)\n\u001b[0m\u001b[0;32m    520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_test_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\keras\\backend\\theano_backend.py\u001b[0m in \u001b[0;36mfunction\u001b[1;34m(inputs, outputs, updates, **kwargs)\u001b[0m\n\u001b[0;32m   1395\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Invalid argument \"%s\" passed to K.function with Theano backend'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1396\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1397\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\keras\\backend\\theano_backend.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputs, outputs, updates, name, **kwargs)\u001b[0m\n\u001b[0;32m   1381\u001b[0m                                         \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1382\u001b[0m                                         \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1383\u001b[1;33m                                         **kwargs)\n\u001b[0m\u001b[0;32m   1384\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\theano\\compile\\function.py\u001b[0m in \u001b[0;36mfunction\u001b[1;34m(inputs, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[0;32m    315\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m                    output_keys=output_keys)\n\u001b[0m\u001b[0;32m    318\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\theano\\compile\\pfunc.py\u001b[0m in \u001b[0;36mpfunc\u001b[1;34m(params, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[0;32m    447\u001b[0m                                          \u001b[0mrebuild_strict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrebuild_strict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m                                          \u001b[0mcopy_inputs_over\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m                                          no_default_updates=no_default_updates)\n\u001b[0m\u001b[0;32m    450\u001b[0m     \u001b[1;31m# extracting the arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[0minput_variables\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcloned_extended_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother_stuff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_vars\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\theano\\compile\\pfunc.py\u001b[0m in \u001b[0;36mrebuild_collect_shared\u001b[1;34m(outputs, inputs, replace, updates, rebuild_strict, copy_inputs_over, no_default_updates)\u001b[0m\n\u001b[0;32m    206\u001b[0m                        ' function to remove broadcastable dimensions.')\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr_sug\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mupdate_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mstore_into\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: ('An update must have the same type as the original shared variable (shared_var=training/Adam/variable, shared_var.type=TensorType(float32, scalar), update_val=Elemwise{add,no_inplace}.0, update_val.type=TensorType(float32, vector)).', 'If the difference is related to the broadcast pattern, you can call the tensor.unbroadcast(var, axis_to_unbroadcast[, ...]) function to remove broadcastable dimensions.')"
     ]
    }
   ],
   "source": [
    "model.fit(x_train[:30],y_train[:30],validation_data=(x_val,y_val),epochs=10,batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用TensorFlow做后端的Attention实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">+ https://github.com/thushv89/attention_keras  这个是基于TensorFlow为后端的keras写的\n",
    "+ 终于注意到这个后端的问题，搜索关键字 keras attention tensorflow backend 找到了另一个attention实现，https://gist.github.com/cbaziotis/6428df359af27d58078ca5ed9792bd6d <br>\n",
    "其中下面有人回答说：\n",
    "This works for me on TF 1.0.1 and Keras 2.0.6, thank you. Did someone test this and tried using/dropping the bias? For me, it doesn't change the results at all. If I initialize the bias with e.g. glorot uniform, the result changes. It seems the bias is not trained and stays all 0's. Any ideas why this might be happening?\n",
    "+ https://github.com/datalogue/keras-attention\n",
    "+ https://gist.github.com/wassname/5292f95000e409e239b9dc973295327a\n",
    "+ https://www.kaggle.com/sermakarevich/hierarchical-attention-network/notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## np.dot theano.dot和tf.matmul(),tf.multiply(),np.dot(),npp.multiply()比较"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考：<br> \n",
    "+ np和tf对比的：https://www.jianshu.com/p/2a83eac1e35e\n",
    "+ theano的：https://blog.csdn.net/guotong1988/article/details/76919838"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "x=tf.constant([[1,2,3],[1,2,3],[1,2,3]])  \n",
    "y=tf.constant([[2,1,1],[2,1,1],[2,1,1]])\n",
    "x1=([[1,2,3],[1,2,3],[1,2,3]])\n",
    "y1=([[2,1,1],[2,1,1],[2,1,1]])\n",
    "z=tf.multiply(x,y)\n",
    "z1=tf.matmul(x,y)\n",
    "z2 = np.dot(x1,y1)\n",
    "print('dot\\n',z2)\n",
    "z3 = np.multiply(x1,y1)\n",
    "print('np.multiply\\n',z3)\n",
    "with tf.Session() as sess:\n",
    "    print('tf.multiply\\n',sess.run(z))\n",
    "    print('tf.matmul\\n',sess.run(z1))\n",
    "    print(sess.run(np.dot(x,y)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python异常处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python提供了两个非常重要的功能来处理python程序在运行中出现的异常和错误。你可以使用该功能来调试python程序。\n",
    "\n",
    "异常处理和断言(Assertions)\n",
    "\n",
    "https://www.runoob.com/python/python-exceptions.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 断言(Assertions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://blog.csdn.net/shijichao2/article/details/61421735\n",
    "\n",
    "https://blog.csdn.net/qq_24753293/article/details/78066426\n",
    "\n",
    "断言一般用在检查参数合法性上：<br>\n",
    "通常情况传递参数不会有误，但编写大量的参数检查影响编程效率，而且不需要检查参数的合法性。\n",
    "\n",
    "    函数原型：assert expression\n",
    "    作为一条特殊的编程语句，检查表达式的正确性，可以理解为“这里一定是成立的”，如果表达式不成立（False），则抛出AssertionError异常, 并且错误可以自己填写。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 过程记录"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在配置过theano之后依然报错：\n",
    "\n",
    "'An update must have the same type as the original shared variable (shared_var=training/Adam/variable, shared_var.type=TensorType(float32, scalar), update_val=Elemwise{add,no_inplace}.0, update_val.type=TensorType(float32, vector)).', 'If the difference is related to the broadcast pattern, you can call the tensor.unbroadcast(var, axis_to_unbroadcast[, ...]) function to remove broadcastable dimensions.'\n",
    "\n",
    "所以决定，在台式机上安装py27版本，安装和这个程序一样的环境去跑一遍。\n",
    "\n",
    "终于想起来本机这个默认的python环境是py3.6 而不是py3.5 而 http://deeplearning.net/software/theano/install_windows.html这个网页里要求明确是\n",
    "\n",
    "Python == 2.7* or ( >= 3.4 and < 3.6 )<br>\n",
    "The conda distribution is highly recommended. Python 2.4 was supported up to and including the release 0.6. Python 2.6 was supported up to and including the release 0.8.2. Python 3.3 was supported up to and including release 0.9.\n",
    "\n",
    "但是py27已经停止支持了，那我笔记本用py35 台式机试试py27好了。都要记得给jupyter添加内核.\n",
    "\n",
    "看到https://stackoverflow.com/questions/47822119/how-can-i-use-blas-functionality-with-pythons-theano-library <br>\n",
    "有人回答:虽然官方不支持3.6 但是在用的过程中没太大问题。\n",
    "\n",
    "在台式机py2.7 import theano之后，<br>\n",
    "**WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.**\n",
    "\n",
    "参考：  https://blog.csdn.net/m0_38058163/article/details/80657447\n",
    "\n",
    "conda install mkl-service 然后改配置文件即可，改成对应的 ldflags=-lmkl_rt就不会再报错了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
