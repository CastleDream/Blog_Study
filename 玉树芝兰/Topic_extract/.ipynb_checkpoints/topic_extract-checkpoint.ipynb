{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA主题提取实例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入数据（观察是否正确）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('datascience.csv',encoding='gb18030')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意上面encoding的格式编码，不是一般的utf-8,所以gb18030这个编码格式的中文文件是可以直接在excel中打开的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>大数据产业迎政策暖风 最新大数据概念股一览</td>\n",
       "      <td>财经热点扒客</td>\n",
       "      <td>大数据产业发展受到国家重视，而大数据已经上升为国家战略，未来发展前景很广阔。大数据产业“十三...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Google发布机器学习平台Tensorflow游乐场～带你一起玩神经网络！</td>\n",
       "      <td>硅谷周边</td>\n",
       "      <td>点击上方“硅谷周边”关注我，收到最新的文章哦！昨天，Google发布了Tensorflow游...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>李克强：中国大数据和云计算产业是开放的</td>\n",
       "      <td>苏州高新区金融办</td>\n",
       "      <td>国务院总理李克强当地时间20日上午在纽约下榻饭店同美国经济、金融、智库、媒体等各界人士座谈，...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>全峰集团持续挖掘大数据</td>\n",
       "      <td>快递物流网</td>\n",
       "      <td>2016年，全峰集团持续挖掘大数据、云计算、“互联网+”等前沿技术和物流快递的融合，并通过优...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>第366期【微理工】贵州理工学院召开大数据分析与应用专题分享会</td>\n",
       "      <td>贵州理工学院</td>\n",
       "      <td>贵州理工学院召开大数据分析与应用专题分享会??借“创响中国”贵安站巡回接力活动暨2016贵安...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    title    author  \\\n",
       "0                   大数据产业迎政策暖风 最新大数据概念股一览    财经热点扒客   \n",
       "1  Google发布机器学习平台Tensorflow游乐场～带你一起玩神经网络！      硅谷周边   \n",
       "2                     李克强：中国大数据和云计算产业是开放的  苏州高新区金融办   \n",
       "3                             全峰集团持续挖掘大数据     快递物流网   \n",
       "4         第366期【微理工】贵州理工学院召开大数据分析与应用专题分享会    贵州理工学院   \n",
       "\n",
       "                                             content  \n",
       "0  大数据产业发展受到国家重视，而大数据已经上升为国家战略，未来发展前景很广阔。大数据产业“十三...  \n",
       "1  点击上方“硅谷周边”关注我，收到最新的文章哦！昨天，Google发布了Tensorflow游...  \n",
       "2  国务院总理李克强当地时间20日上午在纽约下榻饭店同美国经济、金融、智库、媒体等各界人士座谈，...  \n",
       "3  2016年，全峰集团持续挖掘大数据、云计算、“互联网+”等前沿技术和物流快递的融合，并通过优...  \n",
       "4  贵州理工学院召开大数据分析与应用专题分享会??借“创响中国”贵安站巡回接力活动暨2016贵安...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 进行分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意，这次要处理的，是分散的1000多条语句，而不是一整块文本，所以可以使用函数，来一句一句的处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zh_word_cut(sentence):\n",
    "    return \" \".join(jieba.cut(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ join() 方法用于将序列中的元素以指定的字符连接生成一个新的字符串。\n",
    "+ str.join(sequence)\n",
    "+ 这里的空格.join 意思就是把后面分出来字符串用空格连接成一个新的字符串\n",
    "+ 这样** 返回来的就不是字符型列表了，处理起来会更方便，get**\n",
    "\n",
    "> 使用上面那个函数需要用循环来不断调用，来处理数据框（df）里的全部文本，但是这样比较慢，可以使用更高效的apply函数，如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache C:\\Users\\shanshan\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.399 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "df['content_cutted']=df.content.apply(zh_word_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    大 数据 产业 发展 受到 国家 重视 ， 而 大 数据 已经 上升 为 国家 战略 ， 未...\n",
       "1    点击 上方 “ 硅谷 周边 ” 关注 我 ， 收到 最新 的 文章 哦 ！ 昨天 ， Goo...\n",
       "2    国务院 总理 李克强 当地 时间 20 日 上午 在 纽约 下榻 饭店 同 美国 经济 、 ...\n",
       "3    2016 年 ， 全峰 集团 持续 挖掘 大 数据 、 云 计算 、 “ 互联网 + ” 等...\n",
       "4    贵州 理工学院 召开 大 数据分析 与 应用 专题 分享 会 ? ? 借 “ 创响 中国 ”...\n",
       "Name: content_cutted, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.content_cutted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 可以看到，已经分词成功，但是很明显，有错误\n",
    "+ 例如： 大数据 被分成了 大 数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文本向量化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "单词之间已经被空格分开了，形式就像英文一样，这时候可以对文本进行向量化（也就是变成数值形式，方便处理）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer与TfidfVectorizer，这两个类都是特征数值计算的常见方法。\n",
    "+ 对于每一个训练文本，CountVectorizer只考虑每种词汇在该训练文本中出现的频率，\n",
    "+ 而TfidfVectorizer除了考量某一词汇在当前训练文本中出现的频率之外，同时关注包含这个词汇的其它训练文本数目的倒数。\n",
    "+ 相比之下，训练文本的数量越多，TfidfVectorizer这种特征量化方式就更有优势。\n",
    "\n",
    ">+ 词集模型：单词构成的集合，每个单词只出现一次。 sow set of word\n",
    ">+ 词袋模型：把每一个单词都进行统计，同时计算每个单词出现的次数。 bow bag of word\n",
    ">+ Tf-IDF模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于这些文本可能会含有大量的词汇，我们不希望处理所有词汇，所以限定一下，只提取1000个最重要的特征关键词，然后停止\n",
    "+ 看了下数据，content是一个微信公众号内容的完整全文。。所以很大，所以只要抽1k个词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer=CountVectorizer(strip_accents='unicode',\n",
    "                             max_features=1000,\n",
    "                             stop_words='english',\n",
    "                             max_df=0.5,\n",
    "                             min_df=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> strip_accents(重音)：{'ascii'，'unicode'，None}\n",
    "    + 在预处理步骤中删除重音符号。 'ascii'是一种快速方法，仅适用于具有直接ASCII映射的字符。 'unicode'是一个适用于任何字符的稍慢的方法。 无（默认）什么也不做。\n",
    "> stop_words：string {'english'}，列表或无（默认）\n",
    "    + 如果'英语'，则使用内置的英语停用词表。\n",
    "    + 也可以给出自定义的停用词列表，那么所有列表中的词都将从结果标记中删除。 仅适用于分析器=='单词'analyzer == 'word' 单词级别的分析，不是句子级别。\n",
    "    + 如果为None，则不会使用停用词。 可以将max_df设置为范围[0.7,1.0）中的一个值，基于内部语料库文档的词频来过滤停用词\n",
    "    \n",
    "> max_df：[0.0，1.0]范围内的float或int，默认值= 1.0\n",
    "    + 在构建词汇时忽略文档频率严格高于给定阈值（特定语料库的停用词）的词语。 \n",
    "    + 如果为float，则该参数表示文档的比例，若是整数，则表示绝对计数，词出现的次数上限。 \n",
    "    + 如果vocabulary参数是not None，则忽略此参数。\n",
    "\n",
    ">min_df：[0.0，1.0]范围内的浮点数float或int，默认值= 1\n",
    "    + 在构建词汇时忽略文档频率严格低于给定阈值的词语。 这个值在文献中也被称为截断值。\n",
    "    + 如果为float，则该参数表示文档的比例，若是整数，则表示绝对计数，词出现的次数下限。\n",
    "    + 如果vocabulary参数是not None，则忽略此参数。\n",
    "\n",
    ">max_features：int或None，default = None\n",
    "    + 如果不是None，则建立一个词汇表，仅考虑整个语料库中按词频排序的顶级max_features。\n",
    "    + 如果vocabulary参数是not None，则忽略此参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以上面只考虑词频最高的前1000个词，这属于词袋模型\n",
    "<br>** 向量转换的同时只按照频率提取前1000频率的词 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf=tf_vectorizer.fit_transform(df.content_cutted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> sklearn.feature_extraction.text.CountVectorizer.fit_transform(raw_documents, y=None)[source]\n",
    "  学习词汇词典并返回术语 - 文档矩阵。fit_transform相当于fit之后紧接着进行transform，只是更高效一点\n",
    "    + 参数：\n",
    "    + raw_documents：可迭代的，一个可以产生str，unicode或file对象的迭代器。\n",
    "    + 返回：\n",
    "    + X：数组，[n_samples，n_features]，文档术语矩阵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 17)\t1\n",
      "  (0, 332)\t1\n",
      "  (0, 689)\t2\n",
      "  (0, 439)\t1\n",
      "  (0, 209)\t1\n",
      "  (0, 165)\t1\n",
      "  (0, 941)\t1\n",
      "  (0, 10)\t1\n",
      "  (0, 538)\t1\n",
      "  (0, 437)\t1\n",
      "  (0, 297)\t1\n",
      "  (0, 544)\t1\n",
      "  (0, 753)\t1\n",
      "  (0, 99)\t1\n",
      "  (0, 78)\t1\n",
      "  (0, 816)\t1\n",
      "  (0, 625)\t1\n",
      "  (0, 134)\t1\n",
      "  (0, 384)\t1\n",
      "  (0, 93)\t1\n",
      "  (0, 572)\t1\n",
      "  (0, 798)\t1\n",
      "  (0, 502)\t1\n",
      "  (0, 0)\t2\n",
      "  (0, 31)\t1\n",
      "  :\t:\n",
      "  (0, 671)\t1\n",
      "  (0, 575)\t1\n",
      "  (0, 992)\t1\n",
      "  (0, 110)\t2\n",
      "  (0, 514)\t1\n",
      "  (0, 517)\t1\n",
      "  (0, 871)\t1\n",
      "  (0, 580)\t1\n",
      "  (0, 265)\t1\n",
      "  (0, 187)\t2\n",
      "  (0, 361)\t2\n",
      "  (0, 875)\t1\n",
      "  (0, 162)\t4\n",
      "  (0, 275)\t1\n",
      "  (0, 410)\t1\n",
      "  (0, 366)\t1\n",
      "  (0, 686)\t1\n",
      "  (0, 926)\t2\n",
      "  (0, 556)\t1\n",
      "  (0, 117)\t4\n",
      "  (0, 486)\t1\n",
      "  (0, 716)\t4\n",
      "  (0, 847)\t1\n",
      "  (0, 748)\t1\n",
      "  (0, 212)\t1\n"
     ]
    }
   ],
   "source": [
    "print(tf[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以使用类似 print(tf[1]) 这样的语句看一下向量化之后的结果\n",
    "+ 输入tf.shape\n",
    "    + 返回(1024, 1000) \n",
    "    + 也就是1024个记录，其中每个记录1000个关键词？但是很明显，有的句子很短\n",
    "+ 输入tf[1]\n",
    "    + 返回 <1x1000 sparse matrix of type '<class 'numpy.int64'>'with 161 stored elements in Compressed Sparse Row format>,\n",
    "    + 所以返回的是一个1行，1000列的稀疏矩阵，其中每个元素的类型是 以压缩稀疏行格式存储的\n",
    "    + 注意观察返回数据形式，如下，可以发现，元组其实表示的是序号（0行，因为tf中每个元素是一个行向量，所以行号都为0，×列，因为提取词频最高的1k词，所以列号从0到999），后面的 1 是data，\n",
    " + print(tf[11])\n",
    " + (0, 276)\t1\n",
    " + (0, 402)\t1\n",
    " + (0, 760)\t1\n",
    " + ** (0, 999)\t1**\n",
    " + (0, 330)\t1\n",
    " + (0, 588)\t2\n",
    " + (0, 257)\t2\n",
    " + (0, 189)\t4\n",
    " + (0, 666)\t15<br><br>\n",
    " + print(tf[7])\n",
    " + (0, 502)\t1\n",
    " + **(0, 0)\t2**\n",
    " + (0, 31)\t1\n",
    " +  :\t:\n",
    "+ 输入type(tf[1])\n",
    "    + 返回scipy.sparse.csr.csr_matrix ，所以这个就是Compressed Sparse Row 压缩稀疏行矩阵\n",
    "+ tf[1].shape\n",
    "    + 返回(1, 1000)，所以tf中的每个元素都有1k元素\n",
    "+ tf.dtype\n",
    "    + 返回dtype('int64')，所以元素的元素都是整数类型(数字)，已经转为向量了\n",
    "+ 输入tf[1][0,2]\n",
    "    + 因为tf中每个元素都是矩阵，所以可以使用这样的方式访问矩阵中的元素\n",
    "+ sorted(tf.data,reverse=True)\n",
    "    + 从返回的值中可以看到，是从1到319的词\n",
    "    + 虽然指明要词频前1k的词，但是在构建模型的时候，又指定了max_df=0.5,min_df=10，选取了出现次数10次以上，同时最大出现频率是1000多个文档的50%，一共是1024个记录，也就是说那个词语最多在512个记录中出现\n",
    "+ 特征词确定之后，就可以使用模型对这些特征词进行分析了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 主题提取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**应用LDA方法，需要人为设定主题的数量**\n",
    "+ 指定（或者叫瞎猜）主题个数是必须的。\n",
    "    + 如果你只需要把文章粗略划分成几个大类，就可以把数字设定小一些；\n",
    "    + 相反，如果你希望能够识别出非常细分的主题，就增大主题个数。\n",
    "+ 对划分的结果，如果你觉得不够满意，可以通过继续迭代，调整主题数量来优化\n",
    "\n",
    "可以先设定5个分类，试试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.cnblogs.com/pinard/p/6908150.html 这个博客有更详细的函数解释"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_topics=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda=LatentDirichletAllocation(n_topics=5,max_iter=50,\n",
    "                              learning_method='online',\n",
    "                              learning_offset=50.,\n",
    "                              random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> max_iter : integer, optional (default=10)最大迭代次数\n",
    "\n",
    "> random_state : int, RandomState instance or None, optional (default=None)\n",
    "    + 如果是整数，则random_state代表被随机数产生器使用的种子编号\n",
    "    + 如果是RandomState实例，random_state就代表随机数产生器\n",
    "    + 若为None，则随机数产生器就是所使用的RandomState实例\n",
    "    + by `np.random`.\n",
    ">learning_method : 'batch' | 'online', default='online'\n",
    "    用于更新_component的方法，只用于‘fit’方法\n",
    "    通常当数据集很大时，在线（online）更新将比批量(batch)更新快很多\n",
    "    在sklearn0.20版本中，默认的方式将换为batch\n",
    "    有效选项：\n",
    "    + batch:批量变分贝叶斯方法，在每一次EM更新中使用所有的训练数据, 旧的`components_`将在每次迭代中被覆盖。\n",
    "    + online:在线变分贝叶斯方法。 在每次EM更新中，使用 最小批量的训练数据来更新``components_``` 增量可变。 学习速度由 ``learning_decay``和``learning_offset``参数控制\n",
    "    \n",
    "    \n",
    "> learning_decay（衰减） : float, optional (default=0.7)\n",
    "    是控制在线学习方法‘学习率‘的参数.为了保证渐进收敛值应该设置在(0.5,1.0]之间，当值为0.0并且batch_size是‘n_sample’（也就是整个样本数）\n",
    "    此时的更新方法和batch learning一样。用术语来说，叫kappa\n",
    "\n",
    "> learning_offset（补偿，抵消） : float, optional (default=10.)\n",
    "    一个用于降低在线学习早起迭代的（正）参数，应该大于1.0。用术语来说，称为tau_0。\n",
    "     用来减小前面训练样本批次对最终模型的影响。\n",
    "\n",
    "online learning强调的是学习是实时的，流式的，每次训练不用使用全部样本，而是以之前训练好的模型为基础，每来一个样本就更新一次模型，这种方法叫做OGD（online gradient descent）。这样做的目的是快速地进行模型的更新，提升模型时效性。\n",
    "\n",
    "online learning其实细分又可以分为batch模式和delta模式。batch模式的时效性比delta模式要低一些。分析一下batch模式，比如昨天及昨天的数据训练成了模型M，那么今天的每一条训练数据在训练过程中都会更新一次模型M，从而生成今天的模型M1。\n",
    "\n",
    "而batch learning或者叫offline learning强调的是每次训练都需要使用全量的样本，因而可能会面临数据量过大的问题。后面要讨论的批量梯度下降法（BGD）和随机梯度下降法（SGD）都属于batch learning或者offline learning的范畴。\n",
    "\n",
    "batch learning一般进行多轮迭代来向最优解靠近。online learning没有多轮的概念，如果数据量不够或训练数据不够充分，通过copy多份同样的训练数据来模拟batch learning的多轮训练也是有效的方法。\n",
    "\n",
    "+ 批量学习（batch learning），一次性批量输入给学习算法，可以被形象的称为填鸭式学习。\n",
    "+ 在线学习（online learning），按照顺序，循序的学习，不断的去修正模型，进行优化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='online', learning_offset=50.0,\n",
       "             max_doc_update_iter=100, max_iter=50, mean_change_tol=0.001,\n",
       "             n_components=10, n_jobs=1, n_topics=5, perp_tol=0.1,\n",
       "             random_state=0, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.fit(tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面这步可能会比较慢，不要着急，工作量比较大，需要一段时间\n",
    "+ 这时候，就相当于把1000多篇文章向量化后的文章扔给了LDA，让他寻找主题\n",
    "+ 跑完之后，只是返回了这个模型的各种参数，但是并没有看到主题，\n",
    "    + 可以定义下列函数，来把每个主题的前若干个关键字显示出来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words(model,feature_names,n_top_words):\n",
    "    for topic_idx,topic in enumerate(model.components_):\n",
    "        print('Topic #%d:'%topic_idx)\n",
    "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words-1:-1]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "函数定义好之后，暂定每个主题输出前20个关键词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_top_words=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "系统 数据分析 使用 业务 数据库 管理 电子 存储 采集 产品 工具 工作 企业 用户 处理 相关 或者 平台 支持 项目\n",
      "Topic #1:\n",
      "这个 就是 可能 他们 如果 没有 自己 很多 什么 不是 但是 这样 现在 一些 因为 时候 已经 所以 非常 孩子\n",
      "Topic #2:\n",
      "学习 模型 算法 机器 方法 使用 神经网络 特征 训练 深度 分类 可视化 不同 这个 计算 函数 如果 网络 预测 结果\n",
      "Topic #3:\n",
      "企业 中国 互联网 行业 市场 服务 用户 平台 金融 2016 创新 城市 公司 产业 增长 国家 政府 经济 实现 10\n",
      "Topic #4:\n",
      "人工智能 领域 智能 学习 机器人 公司 机器 人类 深度 研究 识别 医疗 未来 系统 目前 已经 语音 服务 计算机 工业\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf_feature_names=tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda,tf_feature_names,n_top_words=n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 在这5个主题里，可以看出主题0主要关注的是数据科学中的算法和技术，而主题4显然更注重数据科学的应用场景\n",
    "+ 只看文字不够直观，可以绘图看看，可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\pyLDAvis\\_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el1404808510941688015300812\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el1404808510941688015300812_data = {\"mdsDat\": {\"x\": [0.17045980425988827, -0.07278783691794216, -0.17340482611553493, -0.02215203494924723, 0.09788489372283614], \"y\": [-0.001112684542412428, 0.11586436370838786, 0.0059910590421239675, -0.17895287130298856, 0.05821013309488909], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [26.233888387017636, 25.02165329023982, 18.321242539529116, 16.86312660573691, 13.560089177476526]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"Freq\": [2789.0, 4217.0, 1456.0, 1116.0, 2007.0, 1853.0, 2194.0, 1779.0, 2250.0, 3205.0, 1343.0, 1022.0, 2438.0, 914.0, 1787.0, 1754.0, 837.0, 1999.0, 728.0, 1131.0, 1529.0, 2239.0, 1622.0, 1367.0, 1330.0, 881.0, 746.0, 742.0, 986.0, 1657.0, 272.6512387061686, 231.89147951773938, 383.30554182367285, 141.13378899660088, 282.23585730532596, 244.3848960771601, 229.2580736949585, 234.4918537817889, 581.3640899679174, 332.57765138911185, 741.0111414560243, 371.4166574202827, 371.4717629154109, 314.73488968645654, 183.94476480188195, 244.1693731170588, 220.96628859577666, 285.46122529938106, 906.3951177361323, 420.39626192718146, 135.8483695520791, 168.8593338597349, 182.19248015785539, 180.93742872829623, 143.87571241199893, 532.4524780824651, 526.7171746755281, 135.2341537500451, 231.38696249108338, 273.2885281114068, 232.17198971341182, 653.3898401696642, 790.0775060315609, 272.40333162931387, 677.1543810690586, 1398.4368896557846, 814.30902314322, 560.7701480727742, 1042.6609179572313, 1151.2917964039589, 2105.1921981277474, 417.7258776141745, 709.8556520893104, 1164.6406184249545, 320.68453787771665, 1027.5480492578417, 317.9209692692874, 942.7768062193851, 373.5313861364112, 483.93326874121567, 1024.2942701146428, 480.327621660595, 554.7201187669883, 505.36542875572525, 729.6460737329, 423.2301163853664, 543.359363001049, 558.3437225000183, 485.6051914442329, 521.9425822203283, 443.9363274503005, 455.3824138372906, 617.9457026045484, 146.14503534825297, 151.77620208646826, 321.58376854338263, 196.64638580277156, 143.7350207411343, 259.35753817334785, 245.63446891768214, 226.66208989023693, 195.40613663043072, 728.4578133812172, 290.1791296921962, 1160.6056754038627, 233.99369159528476, 124.91006010990046, 370.3422715045099, 154.61809474168533, 762.5006201880104, 897.4646536759182, 660.5061699416756, 137.42323869167677, 224.04528486713474, 283.20000527432, 967.7333820976072, 163.6363511827185, 142.31205565540628, 187.16207690776454, 844.1315343189494, 748.9214996655917, 481.45043421325516, 325.7073592910059, 956.0250717487013, 1641.1689089649112, 1314.8951608345242, 1233.864454459293, 791.7605501348094, 1010.1929115727596, 778.423658608059, 431.3741030101948, 1077.1527008875594, 531.7870000115536, 423.8451639460409, 546.9282463887604, 762.2470074783107, 636.1477878260946, 433.0176441965159, 509.0194506811982, 716.9959897207833, 468.4924037567157, 526.1921664712387, 608.3010945224327, 543.5823583819638, 515.788883987615, 560.1926393085458, 553.7947228059405, 524.5118577293277, 479.5612580348048, 269.47434034903466, 334.9547179930986, 301.37358614061714, 173.19454657409116, 148.44288161991608, 181.41741669788968, 156.6144042486383, 163.61955259460112, 144.99840512063807, 216.691045548512, 327.23581250564, 178.71978555958424, 405.2370571764492, 602.6410991553023, 146.4099032090353, 157.50413956503547, 262.2283125959895, 824.5000909000615, 374.1506989704046, 235.82052042581333, 747.9435107157087, 568.6092343841419, 135.64675822864962, 254.08913853175235, 132.2923388503163, 245.11201302612773, 1468.1734785469173, 146.78426451132106, 120.62233099126209, 1468.135508345521, 325.36551486190405, 2537.6926376541232, 989.6173135279693, 395.939235814763, 292.20550948739043, 333.88526823890913, 1021.8117407154667, 564.5646095231898, 347.5811259393505, 922.3215506855935, 601.0085998928896, 330.21696393104025, 521.951323727635, 414.73117617916466, 442.7261683551351, 459.5718036636774, 486.81216341288484, 397.84463408124407, 465.5541589057223, 498.9462865680566, 398.386890355176, 373.95063241770725, 356.27254366723804, 399.4253790585354, 168.02630250307436, 146.18200475048766, 413.444725758368, 293.15761940727907, 156.3936957622783, 293.9197509238517, 695.3860564634912, 205.93979903638393, 381.6937825149358, 266.0426098260557, 756.6347203514885, 179.8750734612487, 664.0629389466036, 642.0111479815863, 338.7662949293832, 189.03720688695324, 196.5263046396547, 126.58054899119321, 117.46517739910749, 118.3349523548303, 340.0524975871177, 248.20824949427382, 144.78826434045243, 313.1737550106227, 107.95146128954624, 118.53279729202069, 148.67198541742246, 107.98364377687878, 115.46772880154403, 407.7926745150848, 798.5893463612659, 592.5089132877183, 963.772645303882, 374.4381443601818, 1050.495479668343, 737.4335038067679, 248.95328740888394, 372.19116668397703, 481.151271625831, 861.8551966721244, 374.99815040432185, 558.4713548108532, 511.4615907436381, 373.2320370105694, 588.3260066846462, 605.8107300842568, 520.8780695410579, 455.08312355513067, 392.42354830047304, 567.6242613501427, 495.07111148459745, 572.9985328752074, 451.22980892043466, 412.73434372753206, 1087.5401606064459, 2704.1181540157, 362.72978503561666, 146.8396169709355, 272.13237090064064, 145.9132514629146, 207.28289260382155, 120.39051786008395, 1183.6752252997987, 203.0420894747163, 159.93773189612432, 315.32801777949925, 137.84964860131495, 473.2175052501387, 239.86404100608883, 127.78132619993178, 234.77367302094075, 145.46722936528772, 126.95847974581325, 117.32895370972436, 1263.793918696758, 297.28607564020365, 635.8303590152855, 111.75861997480843, 90.81949789653619, 144.37306508545166, 167.25544484324246, 91.56531951745323, 329.1608301980571, 197.04576758207745, 491.83058112145414, 623.7837123031255, 871.8589507336549, 910.8600981222685, 348.6701089812058, 406.05447766856344, 1135.9707510499672, 458.2748626516646, 556.2545818974285, 306.8383506019334, 391.8265705791009, 446.9519352567594, 327.77545764563223, 281.3975693539088, 266.89744318052794, 353.94220684593967, 305.31819661510195, 292.71786504376365, 298.39429550398205, 287.8822778296564, 281.9735548701069, 284.9963725095068], \"Term\": [\"\\u4eba\\u5de5\\u667a\\u80fd\", \"\\u5b66\\u4e60\", \"\\u667a\\u80fd\", \"\\u673a\\u5668\\u4eba\", \"\\u9886\\u57df\", \"\\u7b97\\u6cd5\", \"\\u673a\\u5668\", \"\\u6a21\\u578b\", \"\\u8fd9\\u4e2a\", \"\\u4f01\\u4e1a\", \"\\u6df1\\u5ea6\", \"\\u4eba\\u7c7b\", \"\\u516c\\u53f8\", \"\\u795e\\u7ecf\\u7f51\\u7edc\", \"\\u5c31\\u662f\", \"\\u4e2d\\u56fd\", \"\\u6570\\u636e\\u5e93\", \"\\u7cfb\\u7edf\", \"\\u7535\\u5b50\", \"\\u4e1a\\u52a1\", \"\\u65b9\\u6cd5\", \"\\u4f7f\\u7528\", \"\\u6570\\u636e\\u5206\\u6790\", \"\\u7ba1\\u7406\", \"\\u4ed6\\u4eec\", \"\\u7279\\u5f81\", \"\\u91c7\\u96c6\", \"\\u5b58\\u50a8\", \"\\u91d1\\u878d\", \"\\u5982\\u679c\", \"\\u540c\\u6bd4\", \"\\u65c5\\u6e38\", \"\\u5168\\u56fd\", \"\\u5f81\\u4fe1\", \"\\u6709\\u9650\\u516c\\u53f8\", \"00\", \"\\u4fe1\\u7528\", \"\\u96c6\\u56e2\", \"\\u653f\\u5e9c\", \"\\u5927\\u4f17\", \"\\u57ce\\u5e02\", \"\\u6218\\u7565\", \"\\u4fe1\\u606f\\u5316\", \"\\u54c1\\u724c\", \"\\u52a0\\u5f3a\", \"\\u4ebf\\u5143\", \"\\u8d44\\u4ea7\", \"\\u5730\\u533a\", \"\\u91d1\\u878d\", \"\\u94f6\\u884c\", \"\\u9500\\u91cf\", \"\\u6392\\u540d\", \"\\u6708\\u4efd\", \"\\u519c\\u4e1a\", \"\\u52a0\\u5feb\", \"\\u5efa\\u8bbe\", \"\\u8425\\u9500\", \"\\u4eba\\u6570\", \"\\u63a8\\u8fdb\", \"\\u4fc3\\u8fdb\", \"\\u653f\\u7b56\", \"\\u56fd\\u5bb6\", \"\\u521b\\u65b0\", \"\\u5f00\\u5c55\", \"\\u589e\\u957f\", \"\\u4e2d\\u56fd\", \"2016\", \"\\u7ecf\\u6d4e\", \"\\u5e02\\u573a\", \"\\u884c\\u4e1a\", \"\\u4f01\\u4e1a\", \"\\u5f00\\u653e\", \"\\u4ea7\\u4e1a\", \"\\u4e92\\u8054\\u7f51\", \"\\u7535\\u5546\", \"\\u670d\\u52a1\", \"\\u4eba\\u53e3\", \"\\u5e73\\u53f0\", \"\\u6d88\\u8d39\", \"2015\", \"\\u7528\\u6237\", \"\\u8d44\\u6e90\", \"10\", \"\\u63d0\\u5347\", \"\\u516c\\u53f8\", \"\\u79fb\\u52a8\", \"\\u7ba1\\u7406\", \"\\u5b9e\\u73b0\", \"\\u6210\\u4e3a\", \"\\u4ea7\\u54c1\", \"\\u5173\\u6ce8\", \"\\u7f51\\u7edc\", \"\\u5b69\\u5b50\", \"\\u5bb6\\u957f\", \"\\u771f\\u7684\", \"\\u4e8b\\u60c5\", \"\\u8fd9\\u4e48\", \"\\u6709\\u4eba\", \"\\u89c9\\u5f97\", \"\\u4e1c\\u897f\", \"\\u4e0d\\u8981\", \"\\u544a\\u8bc9\", \"\\u65f6\\u5019\", \"\\u4e3a\\u4ec0\\u4e48\", \"\\u4ed6\\u4eec\", \"\\u600e\\u4e48\", \"\\u6bd4\\u5982\\u8bf4\", \"\\u5176\\u5b9e\", \"\\u6210\\u7ee9\", \"\\u73b0\\u5728\", \"\\u4ec0\\u4e48\", \"\\u6240\\u4ee5\", \"\\u76f8\\u4fe1\", \"\\u8001\\u5e08\", \"\\u4eca\\u5929\", \"\\u81ea\\u5df1\", \"\\u53d8\\u6210\", \"\\u7ed3\\u8bba\", \"\\u53d6\\u4ee3\", \"\\u4e0d\\u662f\", \"\\u56e0\\u4e3a\", \"\\u77e5\\u9053\", \"\\u53ea\\u662f\", \"\\u5f88\\u591a\", \"\\u8fd9\\u4e2a\", \"\\u5c31\\u662f\", \"\\u53ef\\u80fd\", \"\\u4f46\\u662f\", \"\\u6ca1\\u6709\", \"\\u8fd9\\u6837\", \"\\u5e94\\u8be5\", \"\\u5982\\u679c\", \"\\u90a3\\u4e48\", \"\\u770b\\u5230\", \"\\u8fd8\\u662f\", \"\\u4e00\\u4e9b\", \"\\u975e\\u5e38\", \"\\u5927\\u5bb6\", \"\\u6bd4\\u5982\", \"\\u5df2\\u7ecf\", \"\\u8fd9\\u79cd\", \"\\u53d1\\u73b0\", \"\\u5de5\\u4f5c\", \"\\u65f6\\u95f4\", \"\\u80fd\\u591f\", \"\\u7528\\u6237\", \"\\u516c\\u53f8\", \"\\u5b66\\u4e60\", \"\\u51fd\\u6570\", \"learning\", \"\\u53d8\\u91cf\", \"\\u5411\\u91cf\", \"\\u68af\\u5ea6\", \"\\u51b3\\u7b56\\u6811\", \"\\u968f\\u673a\", \"\\u8d1d\\u53f6\\u65af\", \"\\u7ebf\\u6027\", \"\\u77e9\\u9635\", \"\\u805a\\u7c7b\", \"\\u56de\\u5f52\", \"\\u795e\\u7ecf\\u5143\", \"\\u53c2\\u6570\", \"\\u8bad\\u7ec3\", \"\\u8bef\\u5dee\", \"\\u6cd5\\u9662\", \"\\u76d1\\u7763\", \"\\u795e\\u7ecf\\u7f51\\u7edc\", \"\\u6837\\u672c\", \"python\", \"\\u7279\\u5f81\", \"\\u5206\\u7c7b\", \"\\u7f16\\u7801\", \"\\u8f93\\u51fa\", \"deep\", \"\\u8ddd\\u79bb\", \"\\u6a21\\u578b\", \"\\u5e8f\\u5217\", \"\\u6240\\u793a\", \"\\u7b97\\u6cd5\", \"\\u8f93\\u5165\", \"\\u5b66\\u4e60\", \"\\u65b9\\u6cd5\", \"\\u4ecb\\u7ecd\", \"http\", \"\\u56fe\\u7247\", \"\\u673a\\u5668\", \"\\u53ef\\u89c6\\u5316\", \"data\", \"\\u4f7f\\u7528\", \"\\u6df1\\u5ea6\", \"\\u8bed\\u8a00\", \"\\u4e0d\\u540c\", \"\\u7ed3\\u679c\", \"\\u9884\\u6d4b\", \"\\u7f51\\u7edc\", \"\\u8ba1\\u7b97\", \"\\u4e00\\u79cd\", \"\\u5982\\u679c\", \"\\u8fd9\\u4e2a\", \"\\u5c31\\u662f\", \"\\u57fa\\u4e8e\", \"\\u5904\\u7406\", \"\\u6570\\u636e\\u4ed3\\u5e93\", \"hive\", \"\\u5ba1\\u67e5\", \"hadoop\", \"sql\", \"apache\", \"\\u5e94\\u5f53\", \"\\u7535\\u5b50\", \"\\u89c4\\u5b9a\", \"\\u67e5\\u8be2\", \"\\u7ed3\\u6784\\u5316\", \"\\u6570\\u636e\\u5e93\", \"spark\", \"\\u5b58\\u50a8\", \"\\u91c7\\u96c6\", \"\\u68c0\\u7d22\", \"\\u4e13\\u5229\", \"\\u5206\\u5e03\\u5f0f\", \"\\u8fdc\\u7a0b\", \"\\u79d1\\u7814\", \"\\u533b\\u9662\", \"\\u5b9e\\u65f6\", \"\\u63d0\\u53d6\", \"\\u539f\\u59cb\", \"\\u67b6\\u6784\", \"\\u4e34\\u5e8a\", \"\\u6570\\u636e\\u6e90\", \"\\u96c6\\u7fa4\", \"\\u68c0\\u67e5\", \"\\u63a5\\u53e3\", \"\\u6536\\u96c6\", \"\\u4e1a\\u52a1\", \"\\u5de5\\u5177\", \"\\u6570\\u636e\\u5206\\u6790\", \"\\u8981\\u6c42\", \"\\u7cfb\\u7edf\", \"\\u7ba1\\u7406\", \"\\u8d28\\u91cf\", \"\\u8bbe\\u5907\", \"\\u652f\\u6301\", \"\\u4f7f\\u7528\", \"\\u529f\\u80fd\", \"\\u5904\\u7406\", \"\\u6216\\u8005\", \"\\u6570\\u636e\\u6316\\u6398\", \"\\u5de5\\u4f5c\", \"\\u4ea7\\u54c1\", \"\\u76f8\\u5173\", \"\\u9879\\u76ee\", \"\\u5f00\\u53d1\", \"\\u7528\\u6237\", \"\\u5e73\\u53f0\", \"\\u4f01\\u4e1a\", \"\\u5b9e\\u73b0\", \"\\u8fc7\\u7a0b\", \"\\u673a\\u5668\\u4eba\", \"\\u4eba\\u5de5\\u667a\\u80fd\", \"\\u8bed\\u97f3\", \"\\u56fe\\u50cf\\u8bc6\\u522b\", \"ai\", \"\\u6536\\u8d2d\", \"\\u611f\\u77e5\", \"\\u5de8\\u5934\", \"\\u667a\\u80fd\", \"\\u5fae\\u8f6f\", \"ibm\", \"\\u767e\\u5ea6\", \"facebook\", \"\\u533b\\u7597\", \"\\u8c37\\u6b4c\", \"\\u4ee3\\u7406\", \"\\u65b0\\u95fb\", \"\\u8ba4\\u77e5\", \"\\u81ea\\u7136\\u8bed\\u8a00\", \"\\u4ebf\\u7f8e\\u5143\", \"\\u9886\\u57df\", \"\\u7814\\u53d1\", \"\\u4eba\\u7c7b\", \"\\u5730\\u56fe\", \"\\u62a5\\u9053\", \"\\u4ea4\\u4e92\", \"\\u6559\\u6388\", \"\\u9769\\u547d\", \"\\u5de5\\u4e1a\", \"google\", \"\\u8bc6\\u522b\", \"\\u6df1\\u5ea6\", \"\\u673a\\u5668\", \"\\u516c\\u53f8\", \"\\u8ba1\\u7b97\\u673a\", \"\\u76ee\\u524d\", \"\\u5b66\\u4e60\", \"\\u672a\\u6765\", \"\\u7814\\u7a76\", \"\\u79d1\\u6280\", \"\\u5df2\\u7ecf\", \"\\u7cfb\\u7edf\", \"\\u65b9\\u9762\", \"\\u5f00\\u53d1\", \"\\u6295\\u8d44\", \"\\u670d\\u52a1\", \"\\u57fa\\u4e8e\", \"\\u5904\\u7406\", \"\\u8ba1\\u7b97\", \"\\u5b9e\\u73b0\", \"\\u4e92\\u8054\\u7f51\", \"\\u4f01\\u4e1a\"], \"Total\": [2789.0, 4217.0, 1456.0, 1116.0, 2007.0, 1853.0, 2194.0, 1779.0, 2250.0, 3205.0, 1343.0, 1022.0, 2438.0, 914.0, 1787.0, 1754.0, 837.0, 1999.0, 728.0, 1131.0, 1529.0, 2239.0, 1622.0, 1367.0, 1330.0, 881.0, 746.0, 742.0, 986.0, 1657.0, 273.4555284274507, 232.69728269675466, 385.39477390695055, 142.507552959688, 290.7122768715207, 254.29922987577072, 238.6973390079339, 244.6416240565952, 611.2313840391688, 351.31149350931406, 788.6037815851361, 398.4672224995856, 398.5478190377252, 337.9103910645673, 198.3671200046289, 263.95663216149717, 239.28619968881725, 309.1941935655996, 986.0019653886515, 459.3647203682113, 148.53925303609284, 184.8950545317748, 199.72570927864277, 198.74986992475047, 158.09271864384283, 586.995220391664, 584.9058605064383, 150.2653453372473, 257.11769952876085, 304.22732107903255, 260.608914691662, 760.374821141147, 943.9837513853388, 308.07134485017235, 805.2893841916333, 1754.0169523311297, 993.0712526823515, 675.8767309641692, 1398.1504231396727, 1577.583503244691, 3205.8869720646203, 499.4925943938016, 928.1085667229918, 1703.5648156994744, 370.78971256929515, 1742.3132537981583, 367.6164425236116, 1733.4681563788351, 462.79240322343855, 702.1219750704456, 2489.023926632924, 727.8724025609079, 972.4444129480241, 856.9501088917357, 2438.7017217326766, 640.3300660750456, 1367.6595061932455, 1645.1210943780081, 1077.546865011392, 1681.6559840461293, 925.8736930231601, 1241.8842116979656, 618.7501318343747, 147.73662221106602, 155.45158660550248, 332.6795879720073, 203.91034336438767, 150.9829152487255, 277.2149370912324, 269.38522989434773, 249.10346472193018, 216.98272973973556, 827.6954266552842, 332.38793755704035, 1330.4165525722708, 268.98082718067496, 144.00104534221728, 427.9746586510647, 179.76837348443266, 897.4132056737005, 1058.7070142464402, 790.435412906017, 164.49320270088745, 268.9840938086235, 341.74879964298384, 1172.328414869972, 198.67784196622745, 172.9351007465465, 227.46512733615668, 1029.633892547563, 916.6040549994775, 591.9366175052587, 402.36195806634566, 1229.801506975333, 2250.8156518816354, 1787.2000082627094, 1722.912887028339, 1092.8652077129252, 1437.4759556635854, 1073.6516342549128, 557.7113840212339, 1657.662853567221, 732.333236897846, 560.049267389146, 780.7453838896269, 1239.940100215868, 976.8030457308455, 593.2604164446723, 747.5339534970003, 1507.8921584097427, 777.9646494438621, 964.0153928935501, 1580.2992878662217, 1289.334017278674, 1237.3663346818296, 2489.023926632924, 2438.7017217326766, 4217.150101617485, 480.4413205952952, 271.0228218694791, 337.031276023639, 303.3634059202796, 175.98434884629867, 151.5616228776779, 187.96013705694293, 162.32068245068191, 169.95140849824122, 151.95872828702863, 227.46983593578085, 343.9793339242842, 187.94156511057176, 428.07919475343607, 656.2354171083305, 159.6042701291287, 172.14184079710154, 287.8573696578724, 914.5004402165837, 427.6275122586742, 271.5068993384887, 881.5796233117436, 670.3281937571696, 162.05684852540944, 304.5247290573819, 159.22010389731935, 296.5815687892418, 1779.596993183812, 179.6080005469869, 149.85670714675052, 1853.4189961953275, 429.83270154292694, 4217.150101617485, 1529.1728807471984, 575.0436489065304, 392.72603271096955, 473.14410217348654, 2194.8486602925423, 1024.2783998766058, 509.88391833212154, 2239.594012179369, 1343.4776722240777, 514.3628025247683, 1476.819401887972, 944.3933698931844, 1114.8240637721967, 1241.8842116979656, 1433.539549317403, 983.7022740182285, 1657.662853567221, 2250.8156518816354, 1787.2000082627094, 1282.4468843941627, 1281.3746175216372, 400.2510489498395, 168.92798401715285, 147.0061032846098, 416.8901588782054, 295.90998771643916, 159.82912741014877, 303.9044130703359, 728.2652898804204, 218.2172200224037, 406.49126442429133, 286.54412865154336, 837.6657336026858, 199.37345547398488, 742.7012907267206, 746.8302797117242, 394.37778933524726, 226.19769544951595, 238.15624211276955, 158.77341080495037, 147.96832790664394, 151.47197145730908, 435.4357190183607, 319.14311081347705, 188.9572966470481, 408.9816758290407, 143.49495884743985, 159.83930281823478, 201.86681781717024, 148.0653619789697, 159.03826804638038, 565.7257962059113, 1131.5640364624892, 896.3438008200932, 1622.737834557989, 585.5680488778761, 1999.2247083507932, 1367.6595061932455, 374.9330010334347, 647.9739193859095, 927.1426810315716, 2239.594012179369, 662.15421732063, 1281.3746175216372, 1133.8223674815697, 710.6669851926489, 1580.2992878662217, 1681.6559840461293, 1292.8613169712346, 1055.611839980968, 799.9473908095896, 2489.023926632924, 1733.4681563788351, 3205.8869720646203, 1645.1210943780081, 1127.903974877674, 1116.6980267984404, 2789.478297764929, 386.84901430177496, 160.613243132672, 312.96584948654663, 169.49068155326103, 246.06516057440547, 145.40713708391164, 1456.1400789915347, 251.3587738021563, 204.8869439658506, 405.16483456791394, 179.6678210552956, 617.5516037696237, 314.39811270219406, 173.18573374214589, 323.66641634531305, 206.36118483891613, 182.34432685671192, 171.8999005829795, 2007.9882298289765, 476.2210355492057, 1022.7286980483433, 180.50595910386852, 147.36641993722785, 235.05211764759298, 272.82433064057307, 149.59059157808386, 539.280137219502, 326.4352764359347, 869.6340775928913, 1343.4776722240777, 2194.8486602925423, 2438.7017217326766, 728.4984031081274, 965.5715486244302, 4217.150101617485, 1243.3371197296826, 1724.594534439167, 767.3978714140943, 1507.8921584097427, 1999.2247083507932, 1056.9712542946224, 799.9473908095896, 768.7018154822449, 1742.3132537981583, 1282.4468843941627, 1281.3746175216372, 1433.539549317403, 1645.1210943780081, 1703.5648156994744, 3205.8869720646203], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.3352, 1.3346, 1.3327, 1.3284, 1.3085, 1.2984, 1.2978, 1.2957, 1.288, 1.2833, 1.2759, 1.2678, 1.2678, 1.2671, 1.2626, 1.2602, 1.2585, 1.2583, 1.2539, 1.2495, 1.2488, 1.2474, 1.2462, 1.2442, 1.2439, 1.2406, 1.2333, 1.2327, 1.2327, 1.2309, 1.2226, 1.1865, 1.1601, 1.2151, 1.1648, 1.1116, 1.1397, 1.1514, 1.0447, 1.0231, 0.9175, 1.1594, 1.07, 0.9578, 1.1929, 0.8101, 1.1929, 0.7291, 1.1238, 0.966, 0.4502, 0.9225, 0.7768, 0.81, 0.1315, 0.9241, 0.415, 0.2575, 0.5411, 0.1681, 0.6031, 0.3349, 1.3841, 1.3746, 1.3615, 1.3515, 1.3492, 1.3362, 1.3188, 1.2931, 1.291, 1.2807, 1.2577, 1.2496, 1.2489, 1.2461, 1.2432, 1.2408, 1.2347, 1.2225, 1.2202, 1.2059, 1.2056, 1.2026, 1.1975, 1.1936, 1.1914, 1.1905, 1.1904, 1.1868, 1.1834, 1.1788, 1.1741, 1.1336, 1.0695, 1.0785, 1.0516, 1.0631, 1.0327, 1.0639, 1.1286, 0.9543, 1.0654, 1.1068, 1.0295, 0.8989, 0.9566, 1.0706, 1.0011, 0.642, 0.8783, 0.78, 0.4307, 0.5217, 0.5104, -0.1059, -0.097, -0.699, 1.6953, 1.6914, 1.6909, 1.6905, 1.6811, 1.6763, 1.6617, 1.6613, 1.6591, 1.6502, 1.6486, 1.6472, 1.6468, 1.6423, 1.6119, 1.6108, 1.6082, 1.6039, 1.5935, 1.5635, 1.5562, 1.5327, 1.5325, 1.5192, 1.516, 1.5118, 1.5065, 1.5047, 1.4953, 1.4801, 1.4641, 1.4187, 1.1892, 1.2619, 1.3239, 1.4015, 1.3485, 0.9326, 1.1014, 1.3139, 0.81, 0.8927, 1.2539, 0.657, 0.8742, 0.7736, 0.703, 0.6171, 0.7918, 0.4272, 0.1906, 0.1961, 0.4647, 0.4171, 1.778, 1.7747, 1.7744, 1.7717, 1.7707, 1.7583, 1.7466, 1.7338, 1.7221, 1.7171, 1.7058, 1.6783, 1.6771, 1.6681, 1.6288, 1.628, 1.6006, 1.5879, 1.5534, 1.5492, 1.5332, 1.5328, 1.5287, 1.5138, 1.5131, 1.4954, 1.4811, 1.4742, 1.4644, 1.4599, 1.4527, 1.4315, 1.3661, 1.259, 1.3329, 1.1365, 1.1624, 1.3706, 1.2256, 1.1241, 0.8251, 1.2115, 0.9496, 0.984, 1.136, 0.792, 0.7591, 0.8709, 0.9386, 1.0678, 0.3019, 0.5269, 0.0582, 0.4864, 0.7747, 1.9716, 1.967, 1.9337, 1.9084, 1.8582, 1.8483, 1.8265, 1.8092, 1.7909, 1.7846, 1.7504, 1.7474, 1.7331, 1.7318, 1.7275, 1.694, 1.6769, 1.6484, 1.636, 1.6161, 1.535, 1.5269, 1.5227, 1.5186, 1.514, 1.5106, 1.5087, 1.5072, 1.5044, 1.4932, 1.4281, 1.2308, 1.0748, 1.0132, 1.2612, 1.1318, 0.6864, 1.0, 0.8665, 1.0814, 0.6504, 0.5, 0.8272, 0.9533, 0.9402, 0.4042, 0.5629, 0.5216, 0.4286, 0.255, 0.1994, -0.4222], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -5.9968, -6.1588, -5.6562, -6.6553, -5.9623, -6.1063, -6.1702, -6.1476, -5.2396, -5.7982, -4.997, -5.6877, -5.6876, -5.8533, -6.3904, -6.1072, -6.207, -5.9509, -4.7955, -5.5638, -6.6935, -6.476, -6.4, -6.4069, -6.6361, -5.3275, -5.3384, -6.698, -6.1609, -5.9945, -6.1575, -5.1229, -4.9329, -5.9977, -5.0871, -4.3619, -4.9027, -5.2757, -4.6555, -4.5564, -3.9529, -5.5702, -5.04, -4.5449, -5.8346, -4.6701, -5.8432, -4.7562, -5.682, -5.4231, -4.6733, -5.4306, -5.2866, -5.3797, -5.0125, -5.5571, -5.3073, -5.2801, -5.4196, -5.3475, -5.5093, -5.4839, -5.1313, -6.5731, -6.5353, -5.7845, -6.2763, -6.5897, -5.9995, -6.0539, -6.1343, -6.2826, -4.9668, -5.8872, -4.501, -6.1024, -6.7301, -5.6433, -6.5168, -4.9211, -4.7581, -5.0647, -6.6346, -6.1459, -5.9116, -4.6828, -6.4601, -6.5997, -6.3257, -4.8194, -4.9391, -5.3809, -5.7717, -4.6949, -4.1546, -4.3762, -4.4398, -4.8835, -4.6398, -4.9004, -5.4907, -4.5756, -5.2815, -5.5083, -5.2534, -4.9214, -5.1023, -5.4869, -5.3252, -4.9826, -5.4082, -5.292, -5.147, -5.2595, -5.312, -5.2294, -5.2409, -5.2952, -5.0732, -5.6496, -5.432, -5.5377, -6.0916, -6.2458, -6.0452, -6.1922, -6.1485, -6.2693, -5.8676, -5.4554, -6.0602, -5.2416, -4.8447, -6.2596, -6.1866, -5.6768, -4.5313, -5.3214, -5.783, -4.6287, -4.9028, -6.336, -5.7083, -6.361, -5.7443, -3.9543, -6.2571, -6.4534, -3.9543, -5.4611, -3.407, -4.3487, -5.2648, -5.5686, -5.4352, -4.3167, -4.91, -5.395, -4.4191, -4.8474, -5.4463, -4.9885, -5.2184, -5.1531, -5.1157, -5.0582, -5.26, -5.1028, -5.0335, -5.2586, -5.3219, -5.3703, -5.1731, -6.039, -6.1783, -5.1386, -5.4824, -6.1107, -5.4798, -4.6186, -5.8355, -5.2185, -5.5794, -4.5342, -5.9708, -4.6647, -4.6985, -5.3378, -5.9212, -5.8823, -6.3222, -6.397, -6.3896, -5.334, -5.6488, -6.1878, -5.4163, -6.4814, -6.3879, -6.1614, -6.4811, -6.4141, -5.1523, -4.4803, -4.7787, -4.2922, -5.2377, -4.2061, -4.5599, -5.6458, -5.2437, -4.9869, -4.404, -5.2362, -4.8379, -4.9258, -5.2409, -4.7858, -4.7565, -4.9076, -5.0426, -5.1908, -4.8216, -4.9584, -4.8122, -5.0511, -5.1403, -3.9534, -3.0426, -5.0514, -5.9558, -5.3388, -5.9621, -5.611, -6.1544, -3.8687, -5.6317, -5.8703, -5.1915, -6.0189, -4.7855, -5.465, -6.0948, -5.4865, -5.9652, -6.1012, -6.1801, -3.8032, -5.2504, -4.4902, -6.2288, -6.4362, -5.9727, -5.8256, -6.4281, -5.1486, -5.6617, -4.747, -4.5093, -4.1745, -4.1307, -5.091, -4.9386, -3.9099, -4.8176, -4.6239, -5.2188, -4.9743, -4.8427, -5.1528, -5.3053, -5.3582, -5.076, -5.2237, -5.2659, -5.2467, -5.2826, -5.3033, -5.2926]}, \"token.table\": {\"Topic\": [1, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 2, 3, 5, 4, 5, 1, 2, 3, 4, 5, 3, 5, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 4, 4, 1, 2, 3, 4, 5, 1, 2, 4, 5, 3, 5, 3, 4, 2, 3, 4, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 1, 4, 5, 1, 2, 3, 4, 5, 2, 3, 4, 1, 2, 3, 4, 5, 2, 4, 5, 1, 2, 3, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 5, 1, 2, 3, 4, 5, 1, 2, 2, 3, 5, 1, 2, 3, 4, 1, 2, 3, 5, 1, 5, 1, 2, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 4, 5, 1, 2, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 4, 5, 1, 4, 5, 1, 3, 1, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 5, 3, 5, 3, 1, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 4, 5, 1, 3, 4, 3, 4, 5, 1, 2, 3, 4, 5, 2, 5, 2, 3, 5, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 5, 1, 2, 3, 1, 2, 4, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 1, 2, 1, 2, 3, 4, 5, 1, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 4, 1, 2, 4, 1, 2, 3, 4, 5, 1, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 5, 1, 2, 3, 4, 5, 1, 3, 4, 5, 1, 2, 4, 5, 1, 2, 3, 5, 1, 2, 1, 2, 3, 4, 1, 5, 1, 2, 3, 4, 5, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 5, 1, 2, 3, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 4, 5, 1, 2, 3, 5, 1, 2, 3, 1, 3, 4, 5, 1, 2, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 1, 2, 3, 4, 1, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 1, 2, 3, 4, 5, 3, 4, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 2, 4, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 1, 2, 3, 1, 3, 1, 2, 4, 5, 1, 2, 3, 4, 5, 3, 5, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 4, 5, 1, 2, 3, 4, 5, 2, 3, 5, 1, 2, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 3, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 4, 2, 3, 1, 2, 3, 4, 5, 2, 3, 4, 5, 1, 2, 4, 5, 2, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 4, 5, 3, 5, 2, 3, 2, 3, 5, 3, 5, 1, 2, 3, 4, 5, 1, 2, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 3, 4, 5, 1, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 4, 5, 1, 2, 4, 5, 1, 2, 3, 4, 1, 2, 3, 2, 3, 5, 1, 2, 5, 1, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5], \"Freq\": [0.959499563247588, 0.031459002073691414, 0.003932375259211427, 0.5707267095272663, 0.14396709789876988, 0.17481719030564916, 0.05964351198663324, 0.0514168206781321, 0.6893389142982445, 0.04415187261001152, 0.11109180850260963, 0.1538194271574595, 0.8196793511053027, 0.010069770898099541, 0.04934187740068775, 0.03625117523315835, 0.08458607554403615, 0.10863805126271947, 0.022366657612912833, 0.8691044101017558, 0.9760423680452026, 0.01877004553933082, 0.03137969138610512, 0.01568984569305256, 0.6825082876477864, 0.25299876180047254, 0.017651076404684128, 0.8290410367093246, 0.16329596177607908, 0.11131653894686397, 0.016697480842029596, 0.10575071199952077, 0.7680841187333614, 0.006126788813501639, 0.030633944067508193, 0.2358813693198131, 0.12559917067678358, 0.6034886981299115, 0.002398713374983146, 0.004797426749966292, 0.9906686238680393, 0.9945066294222832, 0.06875021707529866, 0.0050926086722443455, 0.7435208661476744, 0.17060239052018558, 0.012731521680610864, 0.019522961895838017, 0.09273406900523057, 0.10737629042710908, 0.7809184758335206, 0.9925363411998814, 0.003689726175464243, 0.8692228469147588, 0.12891016797464644, 0.005015712837110778, 0.090282831067994, 0.90282831067994, 0.006758812081451385, 0.990165969932628, 0.037098566287187267, 0.6145458154529717, 0.26291592629615324, 0.050808906002017346, 0.03467909457280549, 0.009149109682583924, 0.3466496001956798, 0.40459396151871135, 0.15553486460392674, 0.08437512262827397, 0.1584486225606553, 0.20584778315572314, 0.35346231186607724, 0.15167731390421704, 0.13068625706925843, 0.012625847006487773, 0.8197088364212062, 0.114603842058889, 0.030107789015470843, 0.024280475012476484, 0.00802879238244464, 0.9112679354074665, 0.0802879238244464, 0.06631367295847532, 0.835552279276789, 0.09726005367243046, 0.24567765591869406, 0.02827944240790723, 0.001767465150494202, 0.7061023276224336, 0.01944211665543622, 0.9131903783161409, 0.07795527619771934, 0.007424312018830414, 0.7970276445401655, 0.09977098554687336, 0.0011402398348214098, 0.0017103597522321148, 0.10034110546428407, 0.08362663118192251, 0.7526396806373026, 0.16725326236384502, 0.006017065524999037, 0.8724745011248604, 0.12034131049998073, 0.00300589527026871, 0.9678982770265246, 0.02705305743241839, 0.00300589527026871, 0.683860096935412, 0.12679294501120086, 0.0005870043750518559, 0.023480175002074236, 0.16553523376462337, 0.01701750250128394, 0.021271878126604922, 0.1106137662583456, 0.23824503501797514, 0.6126300900462218, 0.7649967099289908, 0.0021549203096591293, 0.23273139344318594, 0.3104083147517769, 0.21050678816499813, 0.007730475271595976, 0.36035907804516626, 0.11119991352218828, 0.8650320366983454, 0.13329109999439914, 0.029396177796293502, 0.0010754699193765917, 0.9693568873314345, 0.8984107393292405, 0.04658426055781247, 0.03992936619241069, 0.013309788730803563, 0.000977776415102347, 0.36764393207848256, 0.009777764151023471, 0.6218658000050928, 0.92439427644581, 0.07198152152651799, 0.30831896830804645, 0.005817339024680122, 0.6806286658875743, 0.005667290307196692, 0.8472599009259054, 0.12845858029645835, 0.017001870921590074, 0.0018890967690655639, 0.07315314648103184, 0.8280936181652805, 0.07315314648103184, 0.002926125859241274, 0.02340900687393019, 0.17042184569180288, 0.03825796535938432, 0.6886433764689178, 0.060864944889929606, 0.03999696378481088, 0.019542751441066146, 0.872659016272223, 0.028562482875404367, 0.030817415733988923, 0.04885687860266537, 0.005774147664431111, 0.13280539628191557, 0.12703124861748447, 0.7390909010471822, 0.6566045585332538, 0.07548612976961873, 0.1787336874297171, 0.08889895448074933, 0.011895337053693498, 0.7247005343480961, 0.21686114474810453, 0.01738549261693665, 0.03019585559783734, 0.034827740910102496, 0.09823208974644293, 0.4116817579373654, 0.3848911880065173, 0.07010199131905245, 0.8973553033689559, 0.016435078816281243, 0.0032870157632562485, 0.07888837831814997, 0.9308795137701716, 0.025091092015368507, 0.042654856426126465, 0.9593739123852923, 0.03770465157846127, 0.9937861796031289, 0.0025947419832979867, 0.2993396008599778, 0.2271700532553804, 0.0004100542477533942, 0.0996431822040748, 0.3735594197033421, 0.47954705198530106, 0.2786557193968641, 0.08208463052000649, 0.05724322917842557, 0.10152572722211328, 0.0070097608336337335, 0.8645371694814938, 0.0958000647263277, 0.018692695556356623, 0.014019521667267467, 0.9106924199172013, 0.005031449833796693, 0.08050319734074708, 0.9765004965633522, 0.019793928984392275, 0.9990814266459255, 0.004198924164777882, 0.13436557327289222, 0.8271880604612428, 0.03779031748300094, 0.032819744425026574, 0.011934452518191481, 0.8488379353563691, 0.0551968428966356, 0.05072142320231379, 0.8368788115692026, 0.0370769093733191, 0.0010593402678091173, 0.0031780208034273517, 0.12182413079804849, 0.04530666605340569, 0.08004177669435004, 0.15706310898513973, 0.5663333256675711, 0.14951199797623876, 0.9275730776133986, 0.04537042227456841, 0.015123474091522803, 0.005041158030507601, 0.010082316061015202, 0.9108578891884868, 0.00632540200825338, 0.0316270100412669, 0.05060321606602704, 0.15383329817315078, 0.009715787253041102, 0.0016192978755068504, 0.06962980864679456, 0.7659278951147402, 0.052815051676109746, 0.07922257751416463, 0.7790220122226188, 0.08582445897367834, 0.005292201030309469, 0.2222724432729977, 0.767369149394873, 0.9460866236054075, 0.04905634344620632, 0.002336016354581253, 0.10684476696045206, 0.5456344409825028, 0.20539091124436415, 0.11825537314069451, 0.022821212360484906, 0.8221040393749862, 0.17585113141710934, 0.8254569225081365, 0.09563220443691825, 0.07549910876598809, 0.002967083683740559, 0.9939730340530873, 0.007455973259542913, 0.8102157608703299, 0.08947167911451495, 0.024853244198476374, 0.06958908375573385, 0.019734021525976756, 0.7162288989133917, 0.17702578133596797, 0.042370105041067745, 0.044691754632359124, 0.02538372380314981, 0.0009762970693519158, 0.5516078441838325, 0.2801972589039998, 0.1415630750560278, 0.9983341772972363, 0.992209324281846, 0.0032963764926307176, 0.04147795546122605, 0.898689034993231, 0.055303940614968065, 0.9321998030531424, 0.050309195720328326, 0.017756186724821762, 0.04360727090454149, 0.002907151393636099, 0.9506385057190044, 0.008727868872459396, 0.8171467231840109, 0.15819262331332656, 0.01200081969963167, 0.004363934436229698, 0.8587869848451818, 0.021042253840004455, 0.0013151408650002785, 0.035508803355007515, 0.08285387449501753, 0.08093977648693362, 0.9152420879676341, 0.033816336136286276, 0.03592985714480417, 0.7059160168449761, 0.10356252941737673, 0.12258421849403776, 0.921750815283449, 0.00323421338695947, 0.06145005435222994, 0.009702640160878412, 0.00323421338695947, 0.09971969950112429, 0.2105193656134846, 0.049859849750562145, 0.022159933222472065, 0.6204781302292178, 0.9396353622734982, 0.050722556667935126, 0.0025361278333967566, 0.007608383500190269, 0.17856490025953883, 0.03508917254008405, 0.29163001177758746, 0.2565408392375034, 0.23782661388279192, 0.8406915740974122, 0.08692527354035282, 0.007450737732030242, 0.004967158488020161, 0.06084769147824697, 0.020290709402600575, 0.03745977120480106, 0.2778266364356079, 0.43546984025581237, 0.22866068672930648, 0.9478767593784159, 0.028464767548901378, 0.02561829079401124, 0.12810563100679714, 0.7298649766571469, 0.12810563100679714, 0.011799202855889212, 0.0016856004079841731, 0.016287992423729067, 0.6497099200131927, 0.28111868405399054, 0.04946723624984383, 0.004222812850596424, 0.012117926967911492, 0.002692872659535887, 0.05385745319071774, 0.8940337229659144, 0.03635378090373447, 0.0009485078556880872, 0.12449165605906144, 0.6018282344340913, 0.003556904458830327, 0.26937623101541674, 0.9987876659805295, 0.11712406165248358, 0.03215170319872099, 0.020668952056320633, 0.7808270776832239, 0.048227554798081475, 0.3391847578314411, 0.06625652079503061, 0.1446702013689659, 0.27414395301430095, 0.17506310081622764, 0.9931560441224543, 0.006768802379760218, 0.9882451474449919, 0.024619516448397542, 0.7357878211282448, 0.2226947169650505, 0.003357206788417847, 0.013428827153671387, 0.3764277339170261, 0.012980266686794003, 0.6100725342793182, 0.14744042586680223, 0.3847372486138015, 0.032905159420917235, 0.3720814180672949, 0.06201356967788248, 0.02231286698441086, 0.08925146793764344, 0.12160512506503918, 0.661576506087782, 0.10598611817595158, 0.1444220718538823, 0.020631724550554613, 0.8252689820221846, 0.17972107520328426, 0.47549819527953807, 0.0736126913194264, 0.01193719318693401, 0.2599655405154518, 0.7459855411393072, 0.08654290553965116, 0.0014304612485892753, 0.022887379977428405, 0.14304612485892754, 0.543996148143788, 0.010383807705819922, 0.008076294882304384, 0.28555471191004783, 0.1522958463520255, 0.8184490643641659, 0.17816578271873, 0.026324066568090516, 0.006581016642022629, 0.9674094463773264, 0.0197234632735795, 0.7728011519011604, 0.1416503271466164, 0.057377347704958545, 0.007172168463119818, 0.906310616371, 0.09199393474442481, 0.07250476802143313, 0.0325021373889183, 0.0537535349124418, 0.49003222524830664, 0.35127310024177083, 0.8829123660698942, 0.012984005383380797, 0.009738004037535598, 0.09088803768366559, 0.0032460013458451994, 0.8368492439958928, 0.014014221789404905, 0.02802844357880981, 0.020020316842007006, 0.10210361589423572, 0.9894212416929616, 0.007017171926900437, 0.008131393516173807, 0.777361220146216, 0.1642541490267109, 0.0463489430421907, 0.004065696758086904, 0.003978377141460345, 0.17902697136571552, 0.00795675428292069, 0.80761055971645, 0.8699504810535129, 0.12640306134965573, 0.05283153441817313, 0.08127928372026635, 0.008127928372026635, 0.01625585674405327, 0.8412405865047567, 0.4510244665737689, 0.27005785961515794, 0.02505691480965383, 0.01670460987310255, 0.23850470763263087, 0.06118985106661469, 0.8622206286659343, 0.0667525647999433, 0.005562713733328608, 0.005291834216789281, 0.3228018872241461, 0.19667983839066824, 0.4506878807965537, 0.02381325397555176, 0.931067799435839, 0.06525003446181082, 0.0037953765114983546, 0.8362479580334707, 0.1328381779024424, 0.01771175705365899, 0.008855878526829494, 0.013346082655089008, 0.807438000632885, 0.1534799505335236, 0.026692165310178016, 0.5567828660993785, 0.09366440738120388, 0.0026017890939223297, 0.347338844038631, 0.1221445157429167, 0.2442890314858334, 0.013571612860324078, 0.6175083851447455, 0.9140320190173438, 0.0811271022796459, 0.06916574315806852, 0.006287794832551683, 0.19492163980910218, 0.7230964057434436, 0.8984212305234967, 0.09723173490514032, 0.5892991841183138, 0.14586613468275095, 0.05717952479563837, 0.06068031202802439, 0.14586613468275095, 0.021933733685046218, 0.19113682211254562, 0.7770808505559232, 0.006266781052870349, 0.19198770981177454, 0.022650235427231828, 0.1963020403693425, 0.518798249547548, 0.07010787156047947, 0.11210055813026752, 0.017700088125831716, 0.005900029375277238, 0.8614042887904768, 0.02828225282867668, 0.21565217781865967, 0.02828225282867668, 0.7211974471312553, 0.00707056320716917, 0.9505401966774149, 0.0327208329320969, 0.001636041646604845, 0.004908124939814534, 0.009816249879629068, 0.8902228086651968, 0.0038371672787292964, 0.103603516525691, 0.20526028550501998, 0.0769726070643825, 0.10629550499367106, 0.6121154942738989, 0.9968743393599543, 0.24403202511628433, 0.11462110270613356, 0.03019588189570185, 0.5940577581113589, 0.016638547167019388, 0.011937936098915455, 0.01910069775826473, 0.06207726771436037, 0.9037017626878999, 0.0035813808296746366, 0.0942776312900444, 0.032363962980164494, 0.3377109180538904, 0.5248590518087547, 0.011257030601796347, 0.11886938734715528, 0.10635682025798104, 0.0312814177229356, 0.7444977418058674, 0.1174048281841468, 0.15448003708440367, 0.7260561742966972, 0.01634870740565597, 0.073896157473565, 0.6474088132639765, 0.22888190367918362, 0.03400531140376442, 0.31126674321863235, 0.1920582032625604, 0.04730497617304443, 0.1400227294722115, 0.3103206436951715, 0.9970034772702381, 0.0012081738859437683, 0.8795505889670633, 0.11356834527871422, 0.004832695543775073, 0.16442597275720428, 0.4219232508486751, 0.13185101589021098, 0.2598240607248275, 0.022492232122447754, 0.13528918188724978, 0.03639759715748345, 0.014421689439757591, 0.8131085855558565, 0.9112497367381325, 0.030041200112246126, 0.005006866685374354, 0.05006866685374354, 0.026493063757647674, 0.9537502952753163, 0.019869797818235755, 0.9700312729641924, 0.003439827209092881, 0.013759308836371524, 0.006879654418185762, 0.5900201916957297, 0.03558487537464518, 0.1710369816394236, 0.20317815939716763, 0.2742618993585085, 0.34101772823462634, 0.008847158043822854, 0.00723858385403688, 0.3683634894609879, 0.00045561227891982044, 0.1339500100024272, 0.4656357490560565, 0.003189285952438743, 0.39729390721808344, 0.023282928218778788, 0.0026864917175513986, 0.9743009962319739, 0.02934116785470884, 0.02934116785470884, 0.12225486606128684, 0.7653154615436556, 0.053792141066966205, 0.014760464799896076, 0.017220542266545423, 0.02460077466649346, 0.9397495922600502, 0.004920154933298692, 0.018707870215704824, 0.05846209442407757, 0.8745929325842005, 0.044431191762298955, 0.002338483776963103, 0.011364646987708898, 0.9830419644368197, 0.013507548107599047, 0.1485830291835895, 0.10806038486079238, 0.7294075978103486, 0.022820757769270325, 0.06846227330781098, 0.859581875975849, 0.0481771552906818, 0.03821089845647788, 0.03146779872886414, 0.8249058666780813, 0.08035527175406378, 0.024724699001250395, 0.010701855029561681, 0.6809055262558619, 0.19664658616819589, 0.04146968823955151, 0.07089978957084613, 0.8680492541074166, 0.124999092591468, 0.05217478574476578, 0.7026204480295125, 0.15235037437471607, 0.07443602766253252, 0.018087259058185468, 0.9178477427009154, 0.0813282809988153, 0.8081377252414208, 0.17502448060041467, 0.015125572397566699, 0.0021607960567952425, 0.07220067888394459, 0.014886737914215381, 0.44734647432217217, 0.000744336895710769, 0.46446622292351986, 0.09868649149713289, 0.014746257350146294, 0.8484769613776483, 0.009074619907782334, 0.028358187211819794, 0.012257452788141386, 0.8502214979410798, 0.09583099452546902, 0.00222862777966207, 0.040115300033917264, 0.41140625007379344, 0.2249877930091058, 0.07312103272795938, 0.2282019043378073, 0.062273406993591775, 0.8657198113068194, 0.021575571621353755, 0.0026969464526692194, 0.11327175101210721, 0.02608939388436288, 0.005492503975655343, 0.9543225657701159, 0.012358133945224522, 0.1209384325079836, 0.08391646337288658, 0.01727691892971194, 0.7774613518370375, 0.052109140084994086, 0.03473942672332939, 0.91017298015123, 0.003473942672332939, 0.003473942672332939, 0.3386595229176438, 0.11702913177276375, 0.05488976976952636, 0.06835329820356113, 0.42047634955523966, 0.06079278557293267, 0.8328611623491776, 0.07903062124481247, 0.018237835671879803, 0.29237474664764085, 0.06729260041890146, 0.15701606764410342, 0.4029821243476743, 0.08044172923638795, 0.03392558674092148, 0.7570762514816161, 0.1785557196890604, 0.001785557196890604, 0.028568915150249664, 0.9777963886964901, 0.019298612934799148, 0.013514960493095241, 0.8125869996473514, 0.1723157462869643, 0.03948440519103875, 0.9542064587834364, 0.2918812686207722, 0.014699056693132411, 0.06929555298190994, 0.6236599768371894, 0.25281304752701533, 0.21744241473080445, 0.17395393178464358, 0.033631093478364425, 0.32239462024087273, 0.9524236956028798, 0.047887224918580544, 0.902131878476311, 0.0973208935568384, 0.5590320431948501, 0.02736520491163602, 0.0065155249789609565, 0.0065155249789609565, 0.4000532337082028, 0.11488945127990922, 0.006758203016465248, 0.020274609049395743, 0.7907097529264341, 0.06082382714818723, 0.6605968115675286, 0.07183795113973124, 0.05934439441977798, 0.10463353752960855, 0.10151014834962023, 0.000539543407104808, 0.021581736284192316, 0.792049721629858, 0.035609864868917325, 0.1499930671751366, 0.3970286445866856, 0.027053517218613935, 0.5388768159491478, 0.036558807052180994, 0.05252035929798853, 0.08253199318255341, 0.11604498435365086, 0.5252035929798854, 0.22358667244000835, 0.029420173943729002, 0.9649817053543113, 0.0058840347887458, 0.8300330138599501, 0.09765094280705296, 0.0014795597395008025, 0.07101886749603852, 0.010469591591765604, 0.0069797277278437365, 0.01744931931960934, 0.928303787803217, 0.03838850250314055, 0.02117761585118085, 0.33990073441145263, 0.4394355289120026, 0.1694209268094468, 0.031766423776771274, 0.052042644675070276, 0.8211172826511087, 0.08095522505010931, 0.04626012860006246, 0.012341348225628448, 0.8392116793427346, 0.14809617870754138, 0.36637876197644986, 0.06522347191229107, 0.3704049022179493, 0.16265606575657773, 0.03543003412519515, 0.07435383898287151, 0.832762996608161, 0.037176919491435756, 0.05204768728801006, 0.9539726404043449, 0.04396187282969331, 0.06546161611939115, 0.4170147397235288, 0.14385392184261264, 0.1810296544536249, 0.19315217595721587, 0.04520917460307269, 0.8257071889768748, 0.06824026355180783, 0.017060065887951958, 0.04350316801427749, 0.0054841300370469465, 0.2961430220005351, 0.6964845147049622, 0.9009996917173975, 0.07180642704389126, 0.0034193536687567266, 0.02222579884691872, 0.0034193536687567266, 0.7295968787913182, 0.05831703983388469, 0.0006338808677596162, 0.06782525285027893, 0.14325707611367325, 0.06660199454996851, 0.17248208844991847, 0.056355533849973355, 0.638696050299698, 0.06489425109996932, 0.041243307925359865, 0.00916517953896886, 0.9440134925137925, 0.9342930893899206, 0.06132425683254305, 0.17090564408680575, 0.043947165622321475, 0.33971856600112, 0.2378727536065337, 0.20787706913415557, 0.20178493099343353, 0.19903955778263852, 0.1194237346695831, 0.4790676252837299, 0.043612852906545034, 0.23260188216824018, 0.01938349018068668, 0.7026515190498922, 0.009143060315821887, 0.9188775617400997, 0.07162063914060479, 0.04475488770826386, 0.010802903929580932, 0.003086543979880266, 0.5740971802577295, 0.36729873360575166, 0.06439490061728667, 0.06324499167769226, 0.2403309683752306, 0.06669471849647547, 0.5657551982804472, 0.05443628478296057, 0.6415704992277497, 0.174973772516659, 0.12831409984554992, 0.05945472044568286, 0.9383505879036034, 0.07518595830983303, 0.9147624927696352, 0.20674424360037322, 0.02862612603697475, 0.7633633609859934, 0.9672211675656397, 0.030803221896994894, 0.2240400278675637, 0.0906828684225853, 0.018670002322296975, 0.6641186540359924, 0.0053342863777991354, 0.9235802160233321, 0.012537288000316725, 0.05850734400147805, 0.004179096000105575, 0.6594562430326982, 0.028851210632680546, 0.05495468691939152, 0.15524699054728103, 0.10166617080087431, 0.09103734972548772, 0.06743507387073164, 0.8260796549164626, 0.010115261080609747, 0.003371753693536582, 0.016285405868080322, 0.7561081295894435, 0.19775135696954677, 0.027917838630994837, 0.03283805565135464, 0.8340866135444079, 0.12478461147514763, 0.006567611130270929, 0.07713422590733889, 0.2712996911223644, 0.2580006866555818, 0.36616592298541334, 0.02748460923135064, 0.09734287460192532, 0.7006125316743836, 0.08069211973580652, 0.017931582163512563, 0.10502783838628786, 0.013328501592265283, 0.7290690370969111, 0.22169740981801256, 0.002665700318453057, 0.032876970594254366, 0.009808232221089447, 0.9661108737773106, 0.02452058055272362, 0.01583381374145402, 0.7246298288736015, 0.1825545584308816, 0.026079222632983085, 0.050295643649324526, 0.014139459945723099, 0.6015697504180373, 0.2506540626741822, 0.10411784141850645, 0.02956432534105739, 0.00629828379279751, 0.03149141896398755, 0.05038627034238008, 0.7998820416852838, 0.11336910827035518, 0.017751481627500384, 0.726445248140785, 0.22121077105038942, 0.0068274929336539945, 0.028675470321346777, 0.12050930773018459, 0.008033953848678973, 0.8596330618086501, 0.010711938464905297, 0.9188622657997267, 0.01115616437505187, 0.0010141967613683518, 0.06896537977304792, 0.91430617410789, 0.05659990601620271, 0.008707677848646572, 0.019592275159454785, 0.9155828996053589, 0.013464454405961161, 0.0673222720298058, 0.01064055406276968, 0.9629701426806561, 0.02128110812553936, 0.9565011714681334, 0.016350447375523647, 0.024525671063285473, 0.034676328064674126, 0.19319668493175587, 0.7381104116623494, 0.039630089216770435, 0.04606865242350973, 0.6511036209189375, 0.22420077512774736, 0.03992616543370843, 0.03787866977044133, 0.046794386773623485, 0.33424561981159634, 0.6150119404533372, 0.28893196196577237, 0.10704692361354845, 0.04073467004763348, 0.4310296481784473, 0.13262450713182994, 0.10943430803528968, 0.38660808822303155, 0.39737211852158466, 0.05471715401764484, 0.05202614644300657, 0.19920435491500296, 0.1005981992320765, 0.054781197601625815, 0.01593634839320024, 0.6294857615314094], \"Term\": [\"00\", \"00\", \"00\", \"10\", \"10\", \"10\", \"10\", \"10\", \"2015\", \"2015\", \"2015\", \"2015\", \"2016\", \"2016\", \"2016\", \"2016\", \"2016\", \"ai\", \"ai\", \"ai\", \"apache\", \"apache\", \"data\", \"data\", \"data\", \"data\", \"data\", \"deep\", \"deep\", \"facebook\", \"facebook\", \"facebook\", \"facebook\", \"google\", \"google\", \"google\", \"google\", \"google\", \"hadoop\", \"hadoop\", \"hadoop\", \"hive\", \"http\", \"http\", \"http\", \"http\", \"http\", \"ibm\", \"ibm\", \"ibm\", \"ibm\", \"learning\", \"learning\", \"python\", \"python\", \"spark\", \"spark\", \"spark\", \"sql\", \"sql\", \"\\u4e00\\u4e9b\", \"\\u4e00\\u4e9b\", \"\\u4e00\\u4e9b\", \"\\u4e00\\u4e9b\", \"\\u4e00\\u4e9b\", \"\\u4e00\\u79cd\", \"\\u4e00\\u79cd\", \"\\u4e00\\u79cd\", \"\\u4e00\\u79cd\", \"\\u4e00\\u79cd\", \"\\u4e0d\\u540c\", \"\\u4e0d\\u540c\", \"\\u4e0d\\u540c\", \"\\u4e0d\\u540c\", \"\\u4e0d\\u540c\", \"\\u4e0d\\u662f\", \"\\u4e0d\\u662f\", \"\\u4e0d\\u662f\", \"\\u4e0d\\u662f\", \"\\u4e0d\\u662f\", \"\\u4e0d\\u8981\", \"\\u4e0d\\u8981\", \"\\u4e0d\\u8981\", \"\\u4e13\\u5229\", \"\\u4e13\\u5229\", \"\\u4e13\\u5229\", \"\\u4e1a\\u52a1\", \"\\u4e1a\\u52a1\", \"\\u4e1a\\u52a1\", \"\\u4e1a\\u52a1\", \"\\u4e1a\\u52a1\", \"\\u4e1c\\u897f\", \"\\u4e1c\\u897f\", \"\\u4e1c\\u897f\", \"\\u4e2d\\u56fd\", \"\\u4e2d\\u56fd\", \"\\u4e2d\\u56fd\", \"\\u4e2d\\u56fd\", \"\\u4e2d\\u56fd\", \"\\u4e34\\u5e8a\", \"\\u4e34\\u5e8a\", \"\\u4e34\\u5e8a\", \"\\u4e3a\\u4ec0\\u4e48\", \"\\u4e3a\\u4ec0\\u4e48\", \"\\u4e3a\\u4ec0\\u4e48\", \"\\u4e8b\\u60c5\", \"\\u4e8b\\u60c5\", \"\\u4e8b\\u60c5\", \"\\u4e8b\\u60c5\", \"\\u4e92\\u8054\\u7f51\", \"\\u4e92\\u8054\\u7f51\", \"\\u4e92\\u8054\\u7f51\", \"\\u4e92\\u8054\\u7f51\", \"\\u4e92\\u8054\\u7f51\", \"\\u4ea4\\u4e92\", \"\\u4ea4\\u4e92\", \"\\u4ea4\\u4e92\", \"\\u4ea4\\u4e92\", \"\\u4ea4\\u4e92\", \"\\u4ea7\\u4e1a\", \"\\u4ea7\\u4e1a\", \"\\u4ea7\\u4e1a\", \"\\u4ea7\\u54c1\", \"\\u4ea7\\u54c1\", \"\\u4ea7\\u54c1\", \"\\u4ea7\\u54c1\", \"\\u4ea7\\u54c1\", \"\\u4eba\\u53e3\", \"\\u4eba\\u53e3\", \"\\u4eba\\u5de5\\u667a\\u80fd\", \"\\u4eba\\u5de5\\u667a\\u80fd\", \"\\u4eba\\u5de5\\u667a\\u80fd\", \"\\u4eba\\u6570\", \"\\u4eba\\u6570\", \"\\u4eba\\u6570\", \"\\u4eba\\u6570\", \"\\u4eba\\u7c7b\", \"\\u4eba\\u7c7b\", \"\\u4eba\\u7c7b\", \"\\u4eba\\u7c7b\", \"\\u4ebf\\u5143\", \"\\u4ebf\\u5143\", \"\\u4ebf\\u7f8e\\u5143\", \"\\u4ebf\\u7f8e\\u5143\", \"\\u4ebf\\u7f8e\\u5143\", \"\\u4ec0\\u4e48\", \"\\u4ec0\\u4e48\", \"\\u4ec0\\u4e48\", \"\\u4ec0\\u4e48\", \"\\u4ec0\\u4e48\", \"\\u4eca\\u5929\", \"\\u4eca\\u5929\", \"\\u4eca\\u5929\", \"\\u4eca\\u5929\", \"\\u4eca\\u5929\", \"\\u4ecb\\u7ecd\", \"\\u4ecb\\u7ecd\", \"\\u4ecb\\u7ecd\", \"\\u4ecb\\u7ecd\", \"\\u4ecb\\u7ecd\", \"\\u4ed6\\u4eec\", \"\\u4ed6\\u4eec\", \"\\u4ed6\\u4eec\", \"\\u4ed6\\u4eec\", \"\\u4ed6\\u4eec\", \"\\u4ee3\\u7406\", \"\\u4ee3\\u7406\", \"\\u4ee3\\u7406\", \"\\u4ee3\\u7406\", \"\\u4f01\\u4e1a\", \"\\u4f01\\u4e1a\", \"\\u4f01\\u4e1a\", \"\\u4f01\\u4e1a\", \"\\u4f46\\u662f\", \"\\u4f46\\u662f\", \"\\u4f46\\u662f\", \"\\u4f46\\u662f\", \"\\u4f46\\u662f\", \"\\u4f7f\\u7528\", \"\\u4f7f\\u7528\", \"\\u4f7f\\u7528\", \"\\u4f7f\\u7528\", \"\\u4f7f\\u7528\", \"\\u4fc3\\u8fdb\", \"\\u4fc3\\u8fdb\", \"\\u4fc3\\u8fdb\", \"\\u4fc3\\u8fdb\", \"\\u4fe1\\u606f\\u5316\", \"\\u4fe1\\u606f\\u5316\", \"\\u4fe1\\u606f\\u5316\", \"\\u4fe1\\u7528\", \"\\u4fe1\\u7528\", \"\\u5168\\u56fd\", \"\\u5168\\u56fd\", \"\\u516c\\u53f8\", \"\\u516c\\u53f8\", \"\\u516c\\u53f8\", \"\\u516c\\u53f8\", \"\\u516c\\u53f8\", \"\\u5173\\u6ce8\", \"\\u5173\\u6ce8\", \"\\u5173\\u6ce8\", \"\\u5173\\u6ce8\", \"\\u5173\\u6ce8\", \"\\u5176\\u5b9e\", \"\\u5176\\u5b9e\", \"\\u5176\\u5b9e\", \"\\u5176\\u5b9e\", \"\\u5176\\u5b9e\", \"\\u519c\\u4e1a\", \"\\u519c\\u4e1a\", \"\\u519c\\u4e1a\", \"\\u51b3\\u7b56\\u6811\", \"\\u51b3\\u7b56\\u6811\", \"\\u51fd\\u6570\", \"\\u5206\\u5e03\\u5f0f\", \"\\u5206\\u5e03\\u5f0f\", \"\\u5206\\u5e03\\u5f0f\", \"\\u5206\\u5e03\\u5f0f\", \"\\u5206\\u7c7b\", \"\\u5206\\u7c7b\", \"\\u5206\\u7c7b\", \"\\u5206\\u7c7b\", \"\\u5206\\u7c7b\", \"\\u521b\\u65b0\", \"\\u521b\\u65b0\", \"\\u521b\\u65b0\", \"\\u521b\\u65b0\", \"\\u521b\\u65b0\", \"\\u529f\\u80fd\", \"\\u529f\\u80fd\", \"\\u529f\\u80fd\", \"\\u529f\\u80fd\", \"\\u529f\\u80fd\", \"\\u52a0\\u5f3a\", \"\\u52a0\\u5f3a\", \"\\u52a0\\u5f3a\", \"\\u52a0\\u5f3a\", \"\\u52a0\\u5f3a\", \"\\u52a0\\u5feb\", \"\\u52a0\\u5feb\", \"\\u52a0\\u5feb\", \"\\u52a0\\u5feb\", \"\\u533b\\u7597\", \"\\u533b\\u7597\", \"\\u533b\\u7597\", \"\\u533b\\u7597\", \"\\u533b\\u7597\", \"\\u533b\\u9662\", \"\\u533b\\u9662\", \"\\u533b\\u9662\", \"\\u533b\\u9662\", \"\\u539f\\u59cb\", \"\\u539f\\u59cb\", \"\\u539f\\u59cb\", \"\\u53c2\\u6570\", \"\\u53c2\\u6570\", \"\\u53c2\\u6570\", \"\\u53d1\\u73b0\", \"\\u53d1\\u73b0\", \"\\u53d1\\u73b0\", \"\\u53d1\\u73b0\", \"\\u53d1\\u73b0\", \"\\u53d6\\u4ee3\", \"\\u53d6\\u4ee3\", \"\\u53d8\\u6210\", \"\\u53d8\\u6210\", \"\\u53d8\\u6210\", \"\\u53d8\\u91cf\", \"\\u53d8\\u91cf\", \"\\u53ea\\u662f\", \"\\u53ea\\u662f\", \"\\u53ea\\u662f\", \"\\u53ea\\u662f\", \"\\u53ea\\u662f\", \"\\u53ef\\u80fd\", \"\\u53ef\\u80fd\", \"\\u53ef\\u80fd\", \"\\u53ef\\u80fd\", \"\\u53ef\\u80fd\", \"\\u53ef\\u89c6\\u5316\", \"\\u53ef\\u89c6\\u5316\", \"\\u53ef\\u89c6\\u5316\", \"\\u53ef\\u89c6\\u5316\", \"\\u53ef\\u89c6\\u5316\", \"\\u540c\\u6bd4\", \"\\u5411\\u91cf\", \"\\u5411\\u91cf\", \"\\u544a\\u8bc9\", \"\\u544a\\u8bc9\", \"\\u544a\\u8bc9\", \"\\u54c1\\u724c\", \"\\u54c1\\u724c\", \"\\u54c1\\u724c\", \"\\u56de\\u5f52\", \"\\u56de\\u5f52\", \"\\u56de\\u5f52\", \"\\u56e0\\u4e3a\", \"\\u56e0\\u4e3a\", \"\\u56e0\\u4e3a\", \"\\u56e0\\u4e3a\", \"\\u56e0\\u4e3a\", \"\\u56fd\\u5bb6\", \"\\u56fd\\u5bb6\", \"\\u56fd\\u5bb6\", \"\\u56fd\\u5bb6\", \"\\u56fd\\u5bb6\", \"\\u56fe\\u50cf\\u8bc6\\u522b\", \"\\u56fe\\u50cf\\u8bc6\\u522b\", \"\\u56fe\\u7247\", \"\\u56fe\\u7247\", \"\\u56fe\\u7247\", \"\\u56fe\\u7247\", \"\\u56fe\\u7247\", \"\\u5730\\u533a\", \"\\u5730\\u533a\", \"\\u5730\\u533a\", \"\\u5730\\u533a\", \"\\u5730\\u533a\", \"\\u5730\\u56fe\", \"\\u5730\\u56fe\", \"\\u5730\\u56fe\", \"\\u5730\\u56fe\", \"\\u5730\\u56fe\", \"\\u57ce\\u5e02\", \"\\u57ce\\u5e02\", \"\\u57ce\\u5e02\", \"\\u57ce\\u5e02\", \"\\u57fa\\u4e8e\", \"\\u57fa\\u4e8e\", \"\\u57fa\\u4e8e\", \"\\u57fa\\u4e8e\", \"\\u57fa\\u4e8e\", \"\\u589e\\u957f\", \"\\u589e\\u957f\", \"\\u589e\\u957f\", \"\\u589e\\u957f\", \"\\u589e\\u957f\", \"\\u5904\\u7406\", \"\\u5904\\u7406\", \"\\u5904\\u7406\", \"\\u5904\\u7406\", \"\\u5904\\u7406\", \"\\u5927\\u4f17\", \"\\u5927\\u4f17\", \"\\u5927\\u4f17\", \"\\u5927\\u5bb6\", \"\\u5927\\u5bb6\", \"\\u5927\\u5bb6\", \"\\u5927\\u5bb6\", \"\\u5927\\u5bb6\", \"\\u5982\\u679c\", \"\\u5982\\u679c\", \"\\u5982\\u679c\", \"\\u5982\\u679c\", \"\\u5982\\u679c\", \"\\u5b58\\u50a8\", \"\\u5b58\\u50a8\", \"\\u5b58\\u50a8\", \"\\u5b58\\u50a8\", \"\\u5b58\\u50a8\", \"\\u5b66\\u4e60\", \"\\u5b66\\u4e60\", \"\\u5b66\\u4e60\", \"\\u5b66\\u4e60\", \"\\u5b66\\u4e60\", \"\\u5b69\\u5b50\", \"\\u5b9e\\u65f6\", \"\\u5b9e\\u65f6\", \"\\u5b9e\\u65f6\", \"\\u5b9e\\u65f6\", \"\\u5b9e\\u65f6\", \"\\u5b9e\\u73b0\", \"\\u5b9e\\u73b0\", \"\\u5b9e\\u73b0\", \"\\u5b9e\\u73b0\", \"\\u5b9e\\u73b0\", \"\\u5ba1\\u67e5\", \"\\u5bb6\\u957f\", \"\\u5bb6\\u957f\", \"\\u5c31\\u662f\", \"\\u5c31\\u662f\", \"\\u5c31\\u662f\", \"\\u5c31\\u662f\", \"\\u5c31\\u662f\", \"\\u5de5\\u4e1a\", \"\\u5de5\\u4e1a\", \"\\u5de5\\u4e1a\", \"\\u5de5\\u4f5c\", \"\\u5de5\\u4f5c\", \"\\u5de5\\u4f5c\", \"\\u5de5\\u4f5c\", \"\\u5de5\\u4f5c\", \"\\u5de5\\u5177\", \"\\u5de5\\u5177\", \"\\u5de5\\u5177\", \"\\u5de5\\u5177\", \"\\u5de5\\u5177\", \"\\u5de8\\u5934\", \"\\u5de8\\u5934\", \"\\u5de8\\u5934\", \"\\u5df2\\u7ecf\", \"\\u5df2\\u7ecf\", \"\\u5df2\\u7ecf\", \"\\u5df2\\u7ecf\", \"\\u5df2\\u7ecf\", \"\\u5e02\\u573a\", \"\\u5e02\\u573a\", \"\\u5e02\\u573a\", \"\\u5e02\\u573a\", \"\\u5e02\\u573a\", \"\\u5e73\\u53f0\", \"\\u5e73\\u53f0\", \"\\u5e73\\u53f0\", \"\\u5e73\\u53f0\", \"\\u5e73\\u53f0\", \"\\u5e8f\\u5217\", \"\\u5e8f\\u5217\", \"\\u5e94\\u5f53\", \"\\u5e94\\u5f53\", \"\\u5e94\\u5f53\", \"\\u5e94\\u8be5\", \"\\u5e94\\u8be5\", \"\\u5e94\\u8be5\", \"\\u5e94\\u8be5\", \"\\u5e94\\u8be5\", \"\\u5efa\\u8bbe\", \"\\u5efa\\u8bbe\", \"\\u5f00\\u53d1\", \"\\u5f00\\u53d1\", \"\\u5f00\\u53d1\", \"\\u5f00\\u53d1\", \"\\u5f00\\u53d1\", \"\\u5f00\\u5c55\", \"\\u5f00\\u5c55\", \"\\u5f00\\u5c55\", \"\\u5f00\\u5c55\", \"\\u5f00\\u5c55\", \"\\u5f00\\u653e\", \"\\u5f00\\u653e\", \"\\u5f00\\u653e\", \"\\u5f00\\u653e\", \"\\u5f00\\u653e\", \"\\u5f81\\u4fe1\", \"\\u5f81\\u4fe1\", \"\\u5f88\\u591a\", \"\\u5f88\\u591a\", \"\\u5f88\\u591a\", \"\\u5f88\\u591a\", \"\\u5f88\\u591a\", \"\\u5fae\\u8f6f\", \"\\u5fae\\u8f6f\", \"\\u5fae\\u8f6f\", \"\\u5fae\\u8f6f\", \"\\u600e\\u4e48\", \"\\u600e\\u4e48\", \"\\u611f\\u77e5\", \"\\u611f\\u77e5\", \"\\u611f\\u77e5\", \"\\u611f\\u77e5\", \"\\u611f\\u77e5\", \"\\u6210\\u4e3a\", \"\\u6210\\u4e3a\", \"\\u6210\\u4e3a\", \"\\u6210\\u4e3a\", \"\\u6210\\u4e3a\", \"\\u6210\\u7ee9\", \"\\u6210\\u7ee9\", \"\\u6210\\u7ee9\", \"\\u6210\\u7ee9\", \"\\u6216\\u8005\", \"\\u6216\\u8005\", \"\\u6216\\u8005\", \"\\u6216\\u8005\", \"\\u6216\\u8005\", \"\\u6218\\u7565\", \"\\u6218\\u7565\", \"\\u6240\\u4ee5\", \"\\u6240\\u4ee5\", \"\\u6240\\u4ee5\", \"\\u6240\\u4ee5\", \"\\u6240\\u4ee5\", \"\\u6240\\u793a\", \"\\u6240\\u793a\", \"\\u6240\\u793a\", \"\\u6240\\u793a\", \"\\u6295\\u8d44\", \"\\u6295\\u8d44\", \"\\u6295\\u8d44\", \"\\u6295\\u8d44\", \"\\u62a5\\u9053\", \"\\u62a5\\u9053\", \"\\u62a5\\u9053\", \"\\u62a5\\u9053\", \"\\u6392\\u540d\", \"\\u6392\\u540d\", \"\\u63a5\\u53e3\", \"\\u63a5\\u53e3\", \"\\u63a5\\u53e3\", \"\\u63a5\\u53e3\", \"\\u63a8\\u8fdb\", \"\\u63a8\\u8fdb\", \"\\u63d0\\u5347\", \"\\u63d0\\u5347\", \"\\u63d0\\u5347\", \"\\u63d0\\u5347\", \"\\u63d0\\u5347\", \"\\u63d0\\u53d6\", \"\\u63d0\\u53d6\", \"\\u63d0\\u53d6\", \"\\u63d0\\u53d6\", \"\\u652f\\u6301\", \"\\u652f\\u6301\", \"\\u652f\\u6301\", \"\\u652f\\u6301\", \"\\u652f\\u6301\", \"\\u6536\\u8d2d\", \"\\u6536\\u8d2d\", \"\\u6536\\u8d2d\", \"\\u6536\\u8d2d\", \"\\u6536\\u96c6\", \"\\u6536\\u96c6\", \"\\u6536\\u96c6\", \"\\u6536\\u96c6\", \"\\u6536\\u96c6\", \"\\u653f\\u5e9c\", \"\\u653f\\u5e9c\", \"\\u653f\\u5e9c\", \"\\u653f\\u5e9c\", \"\\u653f\\u5e9c\", \"\\u653f\\u7b56\", \"\\u653f\\u7b56\", \"\\u653f\\u7b56\", \"\\u6559\\u6388\", \"\\u6559\\u6388\", \"\\u6559\\u6388\", \"\\u6559\\u6388\", \"\\u6570\\u636e\\u4ed3\\u5e93\", \"\\u6570\\u636e\\u5206\\u6790\", \"\\u6570\\u636e\\u5206\\u6790\", \"\\u6570\\u636e\\u5206\\u6790\", \"\\u6570\\u636e\\u5206\\u6790\", \"\\u6570\\u636e\\u5206\\u6790\", \"\\u6570\\u636e\\u5e93\", \"\\u6570\\u636e\\u5e93\", \"\\u6570\\u636e\\u5e93\", \"\\u6570\\u636e\\u5e93\", \"\\u6570\\u636e\\u5e93\", \"\\u6570\\u636e\\u6316\\u6398\", \"\\u6570\\u636e\\u6316\\u6398\", \"\\u6570\\u636e\\u6316\\u6398\", \"\\u6570\\u636e\\u6316\\u6398\", \"\\u6570\\u636e\\u6316\\u6398\", \"\\u6570\\u636e\\u6e90\", \"\\u6570\\u636e\\u6e90\", \"\\u6570\\u636e\\u6e90\", \"\\u6570\\u636e\\u6e90\", \"\\u65b0\\u95fb\", \"\\u65b0\\u95fb\", \"\\u65b0\\u95fb\", \"\\u65b9\\u6cd5\", \"\\u65b9\\u6cd5\", \"\\u65b9\\u6cd5\", \"\\u65b9\\u6cd5\", \"\\u65b9\\u6cd5\", \"\\u65b9\\u9762\", \"\\u65b9\\u9762\", \"\\u65b9\\u9762\", \"\\u65b9\\u9762\", \"\\u65b9\\u9762\", \"\\u65c5\\u6e38\", \"\\u65f6\\u5019\", \"\\u65f6\\u5019\", \"\\u65f6\\u5019\", \"\\u65f6\\u5019\", \"\\u65f6\\u95f4\", \"\\u65f6\\u95f4\", \"\\u65f6\\u95f4\", \"\\u65f6\\u95f4\", \"\\u65f6\\u95f4\", \"\\u667a\\u80fd\", \"\\u667a\\u80fd\", \"\\u667a\\u80fd\", \"\\u667a\\u80fd\", \"\\u6708\\u4efd\", \"\\u6708\\u4efd\", \"\\u6708\\u4efd\", \"\\u6708\\u4efd\", \"\\u6709\\u4eba\", \"\\u6709\\u4eba\", \"\\u6709\\u4eba\", \"\\u6709\\u9650\\u516c\\u53f8\", \"\\u6709\\u9650\\u516c\\u53f8\", \"\\u6709\\u9650\\u516c\\u53f8\", \"\\u6709\\u9650\\u516c\\u53f8\", \"\\u670d\\u52a1\", \"\\u670d\\u52a1\", \"\\u670d\\u52a1\", \"\\u670d\\u52a1\", \"\\u672a\\u6765\", \"\\u672a\\u6765\", \"\\u672a\\u6765\", \"\\u672a\\u6765\", \"\\u672a\\u6765\", \"\\u673a\\u5668\", \"\\u673a\\u5668\", \"\\u673a\\u5668\", \"\\u673a\\u5668\", \"\\u673a\\u5668\", \"\\u673a\\u5668\\u4eba\", \"\\u673a\\u5668\\u4eba\", \"\\u673a\\u5668\\u4eba\", \"\\u67b6\\u6784\", \"\\u67b6\\u6784\", \"\\u67b6\\u6784\", \"\\u67b6\\u6784\", \"\\u67b6\\u6784\", \"\\u67e5\\u8be2\", \"\\u67e5\\u8be2\", \"\\u67e5\\u8be2\", \"\\u67e5\\u8be2\", \"\\u67e5\\u8be2\", \"\\u6837\\u672c\", \"\\u6837\\u672c\", \"\\u6837\\u672c\", \"\\u6837\\u672c\", \"\\u6837\\u672c\", \"\\u68af\\u5ea6\", \"\\u68af\\u5ea6\", \"\\u68c0\\u67e5\", \"\\u68c0\\u67e5\", \"\\u68c0\\u67e5\", \"\\u68c0\\u67e5\", \"\\u68c0\\u7d22\", \"\\u68c0\\u7d22\", \"\\u68c0\\u7d22\", \"\\u68c0\\u7d22\", \"\\u6a21\\u578b\", \"\\u6a21\\u578b\", \"\\u6a21\\u578b\", \"\\u6a21\\u578b\", \"\\u6a21\\u578b\", \"\\u6bd4\\u5982\", \"\\u6bd4\\u5982\", \"\\u6bd4\\u5982\", \"\\u6bd4\\u5982\", \"\\u6bd4\\u5982\", \"\\u6bd4\\u5982\\u8bf4\", \"\\u6bd4\\u5982\\u8bf4\", \"\\u6ca1\\u6709\", \"\\u6ca1\\u6709\", \"\\u6ca1\\u6709\", \"\\u6ca1\\u6709\", \"\\u6ca1\\u6709\", \"\\u6cd5\\u9662\", \"\\u6cd5\\u9662\", \"\\u6d88\\u8d39\", \"\\u6d88\\u8d39\", \"\\u6d88\\u8d39\", \"\\u6d88\\u8d39\", \"\\u6df1\\u5ea6\", \"\\u6df1\\u5ea6\", \"\\u6df1\\u5ea6\", \"\\u6df1\\u5ea6\", \"\\u6df1\\u5ea6\", \"\\u7279\\u5f81\", \"\\u7279\\u5f81\", \"\\u7279\\u5f81\", \"\\u7279\\u5f81\", \"\\u7279\\u5f81\", \"\\u73b0\\u5728\", \"\\u73b0\\u5728\", \"\\u73b0\\u5728\", \"\\u73b0\\u5728\", \"\\u73b0\\u5728\", \"\\u7528\\u6237\", \"\\u7528\\u6237\", \"\\u7528\\u6237\", \"\\u7528\\u6237\", \"\\u7528\\u6237\", \"\\u7535\\u5546\", \"\\u7535\\u5546\", \"\\u7535\\u5546\", \"\\u7535\\u5546\", \"\\u7535\\u5b50\", \"\\u7535\\u5b50\", \"\\u7535\\u5b50\", \"\\u7535\\u5b50\", \"\\u767e\\u5ea6\", \"\\u767e\\u5ea6\", \"\\u767e\\u5ea6\", \"\\u767e\\u5ea6\", \"\\u76d1\\u7763\", \"\\u76d1\\u7763\", \"\\u76d1\\u7763\", \"\\u76d1\\u7763\", \"\\u76d1\\u7763\", \"\\u76ee\\u524d\", \"\\u76ee\\u524d\", \"\\u76ee\\u524d\", \"\\u76ee\\u524d\", \"\\u76ee\\u524d\", \"\\u76f8\\u4fe1\", \"\\u76f8\\u4fe1\", \"\\u76f8\\u4fe1\", \"\\u76f8\\u4fe1\", \"\\u76f8\\u5173\", \"\\u76f8\\u5173\", \"\\u76f8\\u5173\", \"\\u76f8\\u5173\", \"\\u76f8\\u5173\", \"\\u770b\\u5230\", \"\\u770b\\u5230\", \"\\u770b\\u5230\", \"\\u770b\\u5230\", \"\\u770b\\u5230\", \"\\u771f\\u7684\", \"\\u771f\\u7684\", \"\\u77e5\\u9053\", \"\\u77e5\\u9053\", \"\\u77e5\\u9053\", \"\\u77e9\\u9635\", \"\\u77e9\\u9635\", \"\\u7814\\u53d1\", \"\\u7814\\u53d1\", \"\\u7814\\u53d1\", \"\\u7814\\u53d1\", \"\\u7814\\u7a76\", \"\\u7814\\u7a76\", \"\\u7814\\u7a76\", \"\\u7814\\u7a76\", \"\\u7814\\u7a76\", \"\\u795e\\u7ecf\\u5143\", \"\\u795e\\u7ecf\\u5143\", \"\\u795e\\u7ecf\\u7f51\\u7edc\", \"\\u795e\\u7ecf\\u7f51\\u7edc\", \"\\u79d1\\u6280\", \"\\u79d1\\u6280\", \"\\u79d1\\u6280\", \"\\u79d1\\u6280\", \"\\u79d1\\u6280\", \"\\u79d1\\u7814\", \"\\u79d1\\u7814\", \"\\u79d1\\u7814\", \"\\u79d1\\u7814\", \"\\u79d1\\u7814\", \"\\u79fb\\u52a8\", \"\\u79fb\\u52a8\", \"\\u79fb\\u52a8\", \"\\u79fb\\u52a8\", \"\\u79fb\\u52a8\", \"\\u7b97\\u6cd5\", \"\\u7b97\\u6cd5\", \"\\u7b97\\u6cd5\", \"\\u7b97\\u6cd5\", \"\\u7b97\\u6cd5\", \"\\u7ba1\\u7406\", \"\\u7ba1\\u7406\", \"\\u7ba1\\u7406\", \"\\u7ba1\\u7406\", \"\\u7cfb\\u7edf\", \"\\u7cfb\\u7edf\", \"\\u7cfb\\u7edf\", \"\\u7cfb\\u7edf\", \"\\u7cfb\\u7edf\", \"\\u7ebf\\u6027\", \"\\u7ebf\\u6027\", \"\\u7ebf\\u6027\", \"\\u7ecf\\u6d4e\", \"\\u7ecf\\u6d4e\", \"\\u7ecf\\u6d4e\", \"\\u7ecf\\u6d4e\", \"\\u7ed3\\u6784\\u5316\", \"\\u7ed3\\u6784\\u5316\", \"\\u7ed3\\u6784\\u5316\", \"\\u7ed3\\u6784\\u5316\", \"\\u7ed3\\u6784\\u5316\", \"\\u7ed3\\u679c\", \"\\u7ed3\\u679c\", \"\\u7ed3\\u679c\", \"\\u7ed3\\u679c\", \"\\u7ed3\\u679c\", \"\\u7ed3\\u8bba\", \"\\u7ed3\\u8bba\", \"\\u7ed3\\u8bba\", \"\\u7ed3\\u8bba\", \"\\u7f16\\u7801\", \"\\u7f16\\u7801\", \"\\u7f16\\u7801\", \"\\u7f51\\u7edc\", \"\\u7f51\\u7edc\", \"\\u7f51\\u7edc\", \"\\u7f51\\u7edc\", \"\\u7f51\\u7edc\", \"\\u8001\\u5e08\", \"\\u8001\\u5e08\", \"\\u8001\\u5e08\", \"\\u8001\\u5e08\", \"\\u805a\\u7c7b\", \"\\u805a\\u7c7b\", \"\\u80fd\\u591f\", \"\\u80fd\\u591f\", \"\\u80fd\\u591f\", \"\\u80fd\\u591f\", \"\\u80fd\\u591f\", \"\\u81ea\\u5df1\", \"\\u81ea\\u5df1\", \"\\u81ea\\u5df1\", \"\\u81ea\\u5df1\", \"\\u81ea\\u5df1\", \"\\u81ea\\u7136\\u8bed\\u8a00\", \"\\u81ea\\u7136\\u8bed\\u8a00\", \"\\u81ea\\u7136\\u8bed\\u8a00\", \"\\u8425\\u9500\", \"\\u8425\\u9500\", \"\\u8425\\u9500\", \"\\u8425\\u9500\", \"\\u8425\\u9500\", \"\\u884c\\u4e1a\", \"\\u884c\\u4e1a\", \"\\u884c\\u4e1a\", \"\\u884c\\u4e1a\", \"\\u884c\\u4e1a\", \"\\u8981\\u6c42\", \"\\u8981\\u6c42\", \"\\u8981\\u6c42\", \"\\u8981\\u6c42\", \"\\u8981\\u6c42\", \"\\u89c4\\u5b9a\", \"\\u89c4\\u5b9a\", \"\\u89c4\\u5b9a\", \"\\u89c9\\u5f97\", \"\\u89c9\\u5f97\", \"\\u8ba1\\u7b97\", \"\\u8ba1\\u7b97\", \"\\u8ba1\\u7b97\", \"\\u8ba1\\u7b97\", \"\\u8ba1\\u7b97\", \"\\u8ba1\\u7b97\\u673a\", \"\\u8ba1\\u7b97\\u673a\", \"\\u8ba1\\u7b97\\u673a\", \"\\u8ba1\\u7b97\\u673a\", \"\\u8ba4\\u77e5\", \"\\u8ba4\\u77e5\", \"\\u8ba4\\u77e5\", \"\\u8ba4\\u77e5\", \"\\u8bad\\u7ec3\", \"\\u8bad\\u7ec3\", \"\\u8bad\\u7ec3\", \"\\u8bbe\\u5907\", \"\\u8bbe\\u5907\", \"\\u8bbe\\u5907\", \"\\u8bbe\\u5907\", \"\\u8bbe\\u5907\", \"\\u8bc6\\u522b\", \"\\u8bc6\\u522b\", \"\\u8bc6\\u522b\", \"\\u8bc6\\u522b\", \"\\u8bc6\\u522b\", \"\\u8bed\\u8a00\", \"\\u8bed\\u8a00\", \"\\u8bed\\u8a00\", \"\\u8bed\\u8a00\", \"\\u8bed\\u97f3\", \"\\u8bed\\u97f3\", \"\\u8bef\\u5dee\", \"\\u8bef\\u5dee\", \"\\u8c37\\u6b4c\", \"\\u8c37\\u6b4c\", \"\\u8c37\\u6b4c\", \"\\u8d1d\\u53f6\\u65af\", \"\\u8d1d\\u53f6\\u65af\", \"\\u8d28\\u91cf\", \"\\u8d28\\u91cf\", \"\\u8d28\\u91cf\", \"\\u8d28\\u91cf\", \"\\u8d28\\u91cf\", \"\\u8d44\\u4ea7\", \"\\u8d44\\u4ea7\", \"\\u8d44\\u4ea7\", \"\\u8d44\\u4ea7\", \"\\u8d44\\u6e90\", \"\\u8d44\\u6e90\", \"\\u8d44\\u6e90\", \"\\u8d44\\u6e90\", \"\\u8d44\\u6e90\", \"\\u8ddd\\u79bb\", \"\\u8ddd\\u79bb\", \"\\u8ddd\\u79bb\", \"\\u8ddd\\u79bb\", \"\\u8ddd\\u79bb\", \"\\u8f93\\u5165\", \"\\u8f93\\u5165\", \"\\u8f93\\u5165\", \"\\u8f93\\u5165\", \"\\u8f93\\u51fa\", \"\\u8f93\\u51fa\", \"\\u8f93\\u51fa\", \"\\u8f93\\u51fa\", \"\\u8fc7\\u7a0b\", \"\\u8fc7\\u7a0b\", \"\\u8fc7\\u7a0b\", \"\\u8fc7\\u7a0b\", \"\\u8fc7\\u7a0b\", \"\\u8fd8\\u662f\", \"\\u8fd8\\u662f\", \"\\u8fd8\\u662f\", \"\\u8fd8\\u662f\", \"\\u8fd8\\u662f\", \"\\u8fd9\\u4e2a\", \"\\u8fd9\\u4e2a\", \"\\u8fd9\\u4e2a\", \"\\u8fd9\\u4e2a\", \"\\u8fd9\\u4e2a\", \"\\u8fd9\\u4e48\", \"\\u8fd9\\u4e48\", \"\\u8fd9\\u4e48\", \"\\u8fd9\\u6837\", \"\\u8fd9\\u6837\", \"\\u8fd9\\u6837\", \"\\u8fd9\\u6837\", \"\\u8fd9\\u6837\", \"\\u8fd9\\u79cd\", \"\\u8fd9\\u79cd\", \"\\u8fd9\\u79cd\", \"\\u8fd9\\u79cd\", \"\\u8fd9\\u79cd\", \"\\u8fdc\\u7a0b\", \"\\u8fdc\\u7a0b\", \"\\u8fdc\\u7a0b\", \"\\u8fdc\\u7a0b\", \"\\u8fdc\\u7a0b\", \"\\u90a3\\u4e48\", \"\\u90a3\\u4e48\", \"\\u90a3\\u4e48\", \"\\u90a3\\u4e48\", \"\\u90a3\\u4e48\", \"\\u91c7\\u96c6\", \"\\u91c7\\u96c6\", \"\\u91c7\\u96c6\", \"\\u91c7\\u96c6\", \"\\u91d1\\u878d\", \"\\u91d1\\u878d\", \"\\u91d1\\u878d\", \"\\u91d1\\u878d\", \"\\u94f6\\u884c\", \"\\u94f6\\u884c\", \"\\u94f6\\u884c\", \"\\u94f6\\u884c\", \"\\u9500\\u91cf\", \"\\u9500\\u91cf\", \"\\u9500\\u91cf\", \"\\u968f\\u673a\", \"\\u968f\\u673a\", \"\\u968f\\u673a\", \"\\u96c6\\u56e2\", \"\\u96c6\\u56e2\", \"\\u96c6\\u56e2\", \"\\u96c6\\u7fa4\", \"\\u96c6\\u7fa4\", \"\\u96c6\\u7fa4\", \"\\u96c6\\u7fa4\", \"\\u975e\\u5e38\", \"\\u975e\\u5e38\", \"\\u975e\\u5e38\", \"\\u975e\\u5e38\", \"\\u975e\\u5e38\", \"\\u9769\\u547d\", \"\\u9769\\u547d\", \"\\u9769\\u547d\", \"\\u9879\\u76ee\", \"\\u9879\\u76ee\", \"\\u9879\\u76ee\", \"\\u9879\\u76ee\", \"\\u9879\\u76ee\", \"\\u9884\\u6d4b\", \"\\u9884\\u6d4b\", \"\\u9884\\u6d4b\", \"\\u9884\\u6d4b\", \"\\u9884\\u6d4b\", \"\\u9886\\u57df\", \"\\u9886\\u57df\", \"\\u9886\\u57df\", \"\\u9886\\u57df\", \"\\u9886\\u57df\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [4, 2, 3, 1, 5]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el1404808510941688015300812\", ldavis_el1404808510941688015300812_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el1404808510941688015300812\", ldavis_el1404808510941688015300812_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el1404808510941688015300812\", ldavis_el1404808510941688015300812_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "3      0.170460 -0.001113       1        1  26.233888\n",
       "1     -0.072788  0.115864       2        1  25.021653\n",
       "2     -0.173405  0.005991       3        1  18.321243\n",
       "0     -0.022152 -0.178953       4        1  16.863127\n",
       "4      0.097885  0.058210       5        1  13.560089, topic_info=     Category         Freq    Term        Total  loglift  logprob\n",
       "term                                                             \n",
       "123   Default  2789.000000    人工智能  2789.000000  30.0000  30.0000\n",
       "366   Default  4217.000000      学习  4217.000000  29.0000  29.0000\n",
       "587   Default  1456.000000      智能  1456.000000  28.0000  28.0000\n",
       "618   Default  1116.000000     机器人  1116.000000  27.0000  27.0000\n",
       "992   Default  2007.000000      领域  2007.000000  26.0000  26.0000\n",
       "781   Default  1853.000000      算法  1853.000000  25.0000  25.0000\n",
       "617   Default  2194.000000      机器  2194.000000  24.0000  24.0000\n",
       "647   Default  1779.000000      模型  1779.000000  23.0000  23.0000\n",
       "931   Default  2250.000000      这个  2250.000000  22.0000  22.0000\n",
       "149   Default  3205.000000      企业  3205.000000  21.0000  21.0000\n",
       "680   Default  1343.000000      深度  1343.000000  20.0000  20.0000\n",
       "126   Default  1022.000000      人类  1022.000000  19.0000  19.0000\n",
       "194   Default  2438.000000      公司  2438.000000  18.0000  18.0000\n",
       "758   Default   914.000000    神经网络   914.000000  17.0000  17.0000\n",
       "403   Default  1787.000000      就是  1787.000000  16.0000  16.0000\n",
       "91    Default  1754.000000      中国  1754.000000  15.0000  15.0000\n",
       "558   Default   837.000000     数据库   837.000000  14.0000  14.0000\n",
       "787   Default  1999.000000      系统  1999.000000  13.0000  13.0000\n",
       "721   Default   728.000000      电子   728.000000  12.0000  12.0000\n",
       "85    Default  1131.000000      业务  1131.000000  11.0000  11.0000\n",
       "574   Default  1529.000000      方法  1529.000000  10.0000  10.0000\n",
       "167   Default  2239.000000      使用  2239.000000   9.0000   9.0000\n",
       "556   Default  1622.000000    数据分析  1622.000000   8.0000   8.0000\n",
       "782   Default  1367.000000      管理  1367.000000   7.0000   7.0000\n",
       "137   Default  1330.000000      他们  1330.000000   6.0000   6.0000\n",
       "694   Default   881.000000      特征   881.000000   5.0000   5.0000\n",
       "957   Default   746.000000      采集   746.000000   4.0000   4.0000\n",
       "364   Default   742.000000      存储   742.000000   3.0000   3.0000\n",
       "961   Default   986.000000      金融   986.000000   2.0000   2.0000\n",
       "362   Default  1657.000000      如果  1657.000000   1.0000   1.0000\n",
       "...       ...          ...     ...          ...      ...      ...\n",
       "126    Topic5   635.830359      人类  1022.728698   1.5227  -4.4902\n",
       "329    Topic5   111.758620      地图   180.505959   1.5186  -6.2288\n",
       "504    Topic5    90.819498      报道   147.366420   1.5140  -6.4362\n",
       "112    Topic5   144.373065      交互   235.052118   1.5106  -5.9727\n",
       "549    Topic5   167.255445      教授   272.824331   1.5087  -5.8256\n",
       "987    Topic5    91.565320      革命   149.590592   1.5072  -6.4281\n",
       "409    Topic5   329.160830      工业   539.280137   1.5044  -5.1486\n",
       "35     Topic5   197.045768  google   326.435276   1.4932  -5.6617\n",
       "888    Topic5   491.830581      识别   869.634078   1.4281  -4.7470\n",
       "680    Topic5   623.783712      深度  1343.477672   1.2308  -4.5093\n",
       "617    Topic5   871.858951      机器  2194.848660   1.0748  -4.1745\n",
       "194    Topic5   910.860098      公司  2438.701722   1.0132  -4.1307\n",
       "872    Topic5   348.670109     计算机   728.498403   1.2612  -5.0910\n",
       "730    Topic5   406.054478      目前   965.571549   1.1318  -4.9386\n",
       "366    Topic5  1135.970751      学习  4217.150102   0.6864  -3.9099\n",
       "612    Topic5   458.274863      未来  1243.337120   1.0000  -4.8176\n",
       "749    Topic5   556.254582      研究  1724.594534   0.8665  -4.6239\n",
       "761    Topic5   306.838351      科技   767.397871   1.0814  -5.2188\n",
       "418    Topic5   391.826571      已经  1507.892158   0.6504  -4.9743\n",
       "787    Topic5   446.951935      系统  1999.224708   0.5000  -4.8427\n",
       "575    Topic5   327.775458      方面  1056.971254   0.8272  -5.1528\n",
       "439    Topic5   281.397569      开发   799.947391   0.9533  -5.3053\n",
       "500    Topic5   266.897443      投资   768.701815   0.9402  -5.3582\n",
       "609    Topic5   353.942207      服务  1742.313254   0.4042  -5.0760\n",
       "336    Topic5   305.318197      基于  1282.446884   0.5629  -5.2237\n",
       "344    Topic5   292.717865      处理  1281.374618   0.5216  -5.2659\n",
       "871    Topic5   298.394296      计算  1433.539549   0.4286  -5.2467\n",
       "382    Topic5   287.882278      实现  1645.121094   0.2550  -5.2826\n",
       "110    Topic5   281.973555     互联网  1703.564816   0.1994  -5.3033\n",
       "149    Topic5   284.996373      企业  3205.886972  -0.4222  -5.2926\n",
       "\n",
       "[309 rows x 6 columns], token_table=      Topic      Freq      Term\n",
       "term                           \n",
       "0         1  0.959500        00\n",
       "0         3  0.031459        00\n",
       "0         4  0.003932        00\n",
       "1         1  0.570727        10\n",
       "1         2  0.143967        10\n",
       "1         3  0.174817        10\n",
       "1         4  0.059644        10\n",
       "1         5  0.051417        10\n",
       "17        1  0.689339      2015\n",
       "17        2  0.044152      2015\n",
       "17        3  0.111092      2015\n",
       "17        5  0.153819      2015\n",
       "18        1  0.819679      2016\n",
       "18        2  0.010070      2016\n",
       "18        3  0.049342      2016\n",
       "18        4  0.036251      2016\n",
       "18        5  0.084586      2016\n",
       "28        2  0.108638        ai\n",
       "28        3  0.022367        ai\n",
       "28        5  0.869104        ai\n",
       "29        4  0.976042    apache\n",
       "29        5  0.018770    apache\n",
       "32        1  0.031380      data\n",
       "32        2  0.015690      data\n",
       "32        3  0.682508      data\n",
       "32        4  0.252999      data\n",
       "32        5  0.017651      data\n",
       "33        3  0.829041      deep\n",
       "33        5  0.163296      deep\n",
       "34        2  0.111317  facebook\n",
       "...     ...       ...       ...\n",
       "979       1  0.956501        集团\n",
       "979       2  0.016350        集团\n",
       "979       5  0.024526        集团\n",
       "981       1  0.034676        集群\n",
       "981       3  0.193197        集群\n",
       "981       4  0.738110        集群\n",
       "981       5  0.039630        集群\n",
       "983       1  0.046069        非常\n",
       "983       2  0.651104        非常\n",
       "983       3  0.224201        非常\n",
       "983       4  0.039926        非常\n",
       "983       5  0.037879        非常\n",
       "987       1  0.046794        革命\n",
       "987       2  0.334246        革命\n",
       "987       5  0.615012        革命\n",
       "988       1  0.288932        项目\n",
       "988       2  0.107047        项目\n",
       "988       3  0.040735        项目\n",
       "988       4  0.431030        项目\n",
       "988       5  0.132625        项目\n",
       "990       1  0.109434        预测\n",
       "990       2  0.386608        预测\n",
       "990       3  0.397372        预测\n",
       "990       4  0.054717        预测\n",
       "990       5  0.052026        预测\n",
       "992       1  0.199204        领域\n",
       "992       2  0.100598        领域\n",
       "992       3  0.054781        领域\n",
       "992       4  0.015936        领域\n",
       "992       5  0.629486        领域\n",
       "\n",
       "[985 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[4, 2, 3, 1, 5])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.sklearn.prepare(lda, tf, tf_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 上面的那个pyLDAvis是专门用于进行LDA的可视化的，也可以和gensim等里面的LDA模型进行交互,但是有个小bug，就是想要让上述图片显示出来，必须翻墙（我的还可以用，开心，带的动）\n",
    "+ 我们规定的是5个主题，所以上面5个圈\n",
    "+ 右边横向柱状图中红色代表的是每个关键词在当前主题（左边的圈）下的概率，所以这里的主题表示是词的概率分布，并没有明确的一句话总结的主题，不像语文\n",
    "<br>** 接下来试试主题数目为10的情况**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_topics=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda=LatentDirichletAllocation(learning_method='online',\n",
    "                             learning_offset=50.,\n",
    "                             random_state=0,\n",
    "                             n_topics=n_topics,\n",
    "                             max_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\decomposition\\online_lda.py:294: DeprecationWarning: n_topics has been renamed to n_components in version 0.19 and will be removed in 0.21\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='online', learning_offset=50.0,\n",
       "             max_doc_update_iter=100, max_iter=50, mean_change_tol=0.001,\n",
       "             n_components=10, n_jobs=1, n_topics=10, perp_tol=0.1,\n",
       "             random_state=0, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.fit(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "系统 存储 使用 数据库 业务 处理 工作 采集 hadoop 数据仓库 查询 支持 项目 开发 架构 sql 计算 数据分析 设备 平台\n",
      "Topic #1:\n",
      "人工智能 学习 机器 人类 机器人 孩子 研究 深度 智能 计算机 领域 已经 能力 未来 工作 系统 他们 能够 可能 教育\n",
      "Topic #2:\n",
      "学习 算法 模型 方法 神经网络 机器 特征 训练 深度 分类 使用 函数 计算 预测 参数 不同 样本 结果 网络 这个\n",
      "Topic #3:\n",
      "企业 管理 服务 平台 建设 互联网 政府 创新 资源 金融 实现 安全 行业 建立 开放 社会 信息化 智慧 国家 能力\n",
      "Topic #4:\n",
      "可视化 使用 data 图表 工具 http 检索 com 新闻 内容 设计 阅读 方式 网站 www 用户 语言 python 创建 专利\n",
      "Topic #5:\n",
      "公司 领域 企业 互联网 中国 产业 智能 服务 人工智能 行业 平台 科技 市场 投资 创新 未来 金融 创业 工业 目前\n",
      "Topic #6:\n",
      "电子 应当 或者 案件 保护 规定 收集 是否 信用卡 法律 提取 申请 法院 通知 无法 相关 要求 记录 审查 检验\n",
      "Topic #7:\n",
      "用户 数据分析 客户 产品 公司 营销 研究 行为 医疗 数据挖掘 消费者 使用 银行 如何 网络 企业 案例 不同 商品 精准\n",
      "Topic #8:\n",
      "这个 就是 如果 可能 没有 很多 什么 他们 时候 但是 不是 自己 所以 一些 因为 这样 现在 非常 那么 已经\n",
      "Topic #9:\n",
      "中国 2016 增长 10 城市 市场 2015 大众 人口 30 关注 全国 同比 其中 20 12 00 行业 11 美国\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_top_words(lda,tf_feature_names,n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "？主题有先后之分吗？为什么可视化里面，有的圆圈大，有的圆圈小？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\pyLDAvis\\_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: if you're in the IPython notebook, pyLDAvis.show() is not the best command\n",
      "      to use. Consider using pyLDAvis.display(), or pyLDAvis.enable_notebook().\n",
      "      See more information at http://pyLDAvis.github.io/quickstart.html .\n",
      "\n",
      "You must interrupt the kernel to end this command\n",
      "\n",
      "Serving to http://127.0.0.1:8889/    [Ctrl-C to exit]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [29/Jun/2018 16:32:20] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Jun/2018 16:32:20] \"GET /LDAvis.css HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Jun/2018 16:32:20] \"GET /d3.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Jun/2018 16:32:20] \"GET /LDAvis.js HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Jun/2018 16:32:20] code 404, message Not Found\n",
      "127.0.0.1 - - [29/Jun/2018 16:32:20] \"GET /favicon.ico HTTP/1.1\" 404 -\n"
     ]
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.sklearn.prepare(lda, tf, tf_vectorizer)\n",
    "data = pyLDAvis.sklearn.prepare(lda, tf, tf_vectorizer)\n",
    "pyLDAvis.show(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 如果只使用前两天语句，由于pyLDAvis包兼容性有些问题。因此在某些操作系统和软件环境下，执行了刚刚的语句后，没有报错，却也没有图形显示出来。所以可以添加后两句语句，这样会显示在一个新的标签页中\n",
    "2. Jupyter会给你提示一些警告。不用管它。因为此时你的浏览器会弹出一个新的标签页，结果图形会在这个标签页里正确显示出来。\n",
    "3. 如果你看完了图后，需要继续程序，就回到原先的标签页，点击Kernel菜单下的第一项Interrupt停止绘图，然后往下运行新的语句。\n",
    "4. **图的左侧，用圆圈代表不同的主题，圆圈的大小代表了每个主题分别包含文章的数量。**\n",
    "    + 图左侧的标识是  Marginal topic distribtion边际主题分布\n",
    "5. **图的右侧，列出了最重要（频率最高）的30个关键词列表。注意当你没有把鼠标悬停在任何主题之上的时候，这30个关键词代表全部文本中提取到的30个最重要关键词。**\n",
    " + 图右侧的表示，蓝色代表全部文本里最高频率的词，红色代表所选主题的最高频率的词\n",
    "\n",
    "\n",
    "6. 之前翻墙的话，只是前两个语句也可以运行，两种方法，都知道一下，没问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "观察可视化图发现，当主题数为10个时，编号为10的主题似乎与其他主题格格不入，其他的都抱团，就它一个自己呆着，观察发现，这个主题是法律类的，和其他科技类的肯定格格不入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另外，不论是5个还是10个主题，可能都不是最优的数量选择。你可以根据程序反馈的结果不断尝试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
