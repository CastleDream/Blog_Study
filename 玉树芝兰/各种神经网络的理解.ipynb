{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考网址：\n",
    "https://www.jianshu.com/p/9b4c379155d9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "François Chollet 在他的 \"Deep Learning with Python\" 一书中，也提到过这种观点（注意这里说的是 RNN 的一个变种，叫做 LSTM）：\n",
    "\n",
    "> you don’t need to understand anything about the specific architecture of an LSTM cell; as a human, it shouldn’t be your job to understand it.\n",
    "\n",
    "但是注意， François Chollet 后面还有一句话：\n",
    "\n",
    ">Just keep in mind what the LSTM cell is meant to do.\n",
    "\n",
    "不需要知道一个LSTM细胞的具体实现结构，这不是你的事，但是你要知道LSTM细胞是干嘛的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "视频网址：https://v.qq.com/x/page/i0644wf0dsg.html\n",
    "\n",
    "这是卷积神经网络\n",
    "\n",
    "为什么要使用卷积层，这个视频里26分钟左右给了一个很合理的解释：如果直接把一个图像矩阵变成一列数，全连接扔进神经网络，会丢失很多有用的信息。其实就是位置信息。例如：有一个图像是3\\*4，还有一个图像是2\\*6  如果这两个矩阵变成一列数据后内容一样，那就有问题了，因为其实这两个图像是不一样，这就是丢失了向量信息，像素之间的相对位置信息在输入全连接层之后丢失了\n",
    "\n",
    "视频网址：https://v.qq.com/x/page/o0793dmqjss.html\n",
    "\n",
    "这是循环神经网络\n",
    "\n",
    "学到了一个东西 ，dense layer 基本等于或者说就是 fully connected layer 稠密层其实就是全连接层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
