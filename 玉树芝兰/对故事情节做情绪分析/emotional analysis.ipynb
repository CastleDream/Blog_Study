{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "情绪分析(emotional analysis)。它和情感分析(sentiment analysis)有相似之处。都是通过对内容的自动化分析，来获得结果。\n",
    "\n",
    "情感分析的结果一般分为正向(positive)和负向(negative)，而情绪分析包含的种类就比较多了。\n",
    "\n",
    "加拿大国家研究委员会(National Research Council of Canada)官方发布的情绪词典包含了8种情绪，分别为：\n",
    "\n",
    "愤怒(anger)\n",
    "期待(anticipation)\n",
    "厌恶(disgust)\n",
    "恐惧(fear)\n",
    "喜悦(joy)\n",
    "悲伤(sadness)\n",
    "惊讶(surprise)\n",
    "信任(trust)\n",
    "有了这些情绪的标记，你可以轻松地对一段文本的情绪变化进行分析。\n",
    "\n",
    "这时候，你可以回忆起中学语文老师讲作文时说过的那句话：\n",
    "\n",
    "文如看山不喜平。\n",
    "\n",
    "故事情节会伴随着各种情绪的波动。通过分析这些情绪的起伏，我们可以看出故事的基调是否符合自己的口味，情节是否紧凑等。这样，你可以根据自己的偏好，甚至是当前的心境，来选择合适的作品观看了。\n",
    "\n",
    "**我们需要用到Python和R。这两种语言在目前数据科学领域里最受欢迎。Python的优势在于通用，而R的优势在于统计学家组成的社区。这些统计学家真是高产，也很酷，经常制造出令人惊艳的分析包。**\n",
    "+ //但是这个文章写与2017.8.29，所以python库更新的能力肯定是越来越强的，今天是2018.7.2\n",
    "\n",
    "咱们这里就用Python来做数据清理，然后用R做情绪分析，并且把结果可视化输出。\n",
    "\n",
    "作者：王树义\n",
    "链接：https://www.jianshu.com/p/0c782715e58a\n",
    "來源：简书\n",
    "简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。\n",
    "\n",
    "** 我会尽力全部使用python，自己去找相关的库来完成**\n",
    "\n",
    "但是几乎找不到，还是我太天真，去试水R好了，也不能用中文了，哎\n",
    "\n",
    "教程给的是权力的游戏的剧本，我用教父的剧本好了\n",
    "\n",
    "https://www.douban.com/note/513904663/\n",
    "\n",
    "中文"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先需要清理文本数据，完成以下两个任务：\n",
    "\n",
    "1. 把与剧情正文无关的内容去除；\n",
    "2. 将数据转换成R可以直接做情绪分析的结构化数据格式，（我就是转成python可以直接做情绪分析的结构化数据格式）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 教父"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('theGodFather.txt',encoding='utf8') as f:\n",
    "    data=f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 如果上面使用f.readlines(),则data就成为了list类型，无法直接使用split（）函数。\n",
    "+ 使用print(data)，数据正确读入，接下来去掉非正文的文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.split('另一黑帮收买')[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 解释一下上面这个命令，data是str类型，S.split(sep=None, maxsplit=-1) 返回str列表\n",
    "+ 返回S中单词的一个使用分隔字符串分隔的列表，如果给出了maxsplit，则最多分隔maxsplit次。\n",
    "+ 如果没有明确给出分隔符，则任意空白字符都是分隔符，空白字符串将结果中移除。\n",
    "\n",
    "这里其实就是以‘'另一黑帮收买’为分隔，分为前后两部分，取[1]，也就是后面部分\n",
    "\n",
    "删除了不属于正文部分的开头部分,可以先用print(data)看一下\n",
    "\n",
    "然后以同样方式处理结尾部分，但是这个剧本结尾没有多余的废话\n",
    "\n",
    "**移除了开头和结尾的多余内容后，我们来移除空行。这里我们需要用到正则表达式**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "解释下这句代码：也就是把空行用空字符\"\"代替\n",
    "re.sub(pattern, repl, string, count=0, flags=0)\n",
    "    \n",
    "re.sub功能是对于一个输入的字符串，利用正则表达式，来实现字符串替换处理的功能返回处理后的字符串\n",
    "   \n",
    "re.sub共有五个参数，三个必选参数 pattern，repl，string，两个可选参数count，flags\n",
    "\n",
    "https://blog.csdn.net/MHSMIE/article/details/71941328\n",
    "\n",
    "这个博客写的不错"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = r'^\\s*|\\s*$'\n",
    "subst = \"\"\n",
    "data=re.sub(regex, subst, data, 0, re.MULTILINE)\n",
    "# 由于我使用这个正则一直无效，所以最简单粗暴的就是不用正则，反正都知道要去除的字符长得很规范，直接替换就好了,\n",
    "# 但是这样替换把该有换行的地方都删掉了，不行，我要的只是去掉空行的换行符\n",
    "# 后来找到了全角匹配的办法，\n",
    "# regex = r'$\\n[\\u0391-\\uFFE5]{2}'但是这样之后也是把所有空格都删除了\n",
    "# 最后，在同一个网站找到上面这个正则，满足只删除空行，但不删除有意义的换行符,即删除了\\u3000，和多余的\\n，但是有用的换行保留"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 后来按照这样的正则模式执行之后，发现空行还是没有删除，\n",
    "+ 直接  data （不是print(data）)\n",
    "+ 显示出了\\n\\u3000\\u3000 \\n\\u3000\\u3000 这样的字符串，百度发现,\\u3000这是中文全角空格，所以我的正则应该由\n",
    "    + \\u3000 是全角的空白符,根据Unicode编码标准及其基本多语言面的定义， \\u3000 属于CJK字符的CJK标点符号区块内，是空白字符之一。它的名字是 Ideographic Space ，有人译作表意字空格、象形字空格等。顾名思义，就是全角的 CJK 空格。它跟 nbsp 不一样，是可以被换行间断的。常用于制造缩进， wiki 还说用于抬头，但没见过。\n",
    "\n",
    "+ \\s 空白字符：[ \\t\\n\\x0B\\f\\r] \n",
    "+ \\S 非空白字符：[^\\s] \n",
    "\n",
    "\n",
    "+ regex=r\"^$\\n\" 改为 regex=r\"^$\\n\\n\\u3000\\u3000\"\n",
    "\n",
    "\n",
    "+ 注意，markdown语法把$$之间的文本括起来了，所以我用了转义，把$弄好"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "进一步百度，发现：\n",
    "\n",
    "**在对文本进行处理的时候经常会遇见要对括号和标点进行匹配，常见的英文(半角)符号如( ) 直接用正则匹配即可\n",
    "，但是遇见全角字符(中文括号、标点)，直接用正则匹配会存在问题：因为编码通常为为utf8，若直接匹配，中文括号的3字节编码会和一些中文的字节编码重复，产生意想不到的结果，若用decode转为unicode编码，则可避免产生错误结果，但也无法直接用正则匹配到**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来利用换行符把文本进行分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines=data.split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后给每一行加上行号，这个可以直接用pandas的DataFrame来做吧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1293"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['line']=range(1,1294)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以使用df['line']来看看序号是否正确"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text']=lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.堂科列奥办公室</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>随着片名《教父》的出现，声带上旁白：“我信任美国。”接着，身穿黑色西服、年约六十、神情紧张的...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>波拿塞那：我在美国成了家立了业。（画面后景逐渐出现）我把女儿以美国方式培养成人。我给她自由，...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>此人此时是在“教父”堂科列奥（注1）的办公室内，百叶窗放下了，房间中暗沉沉的。墙上映着百叶窗...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>堂科列奥：波拿塞那，我们是多年的老相识了，可这还是你第一次来求助于我。你最后一次请我上你家去...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   line                                               text\n",
       "0     1                                          1.堂科列奥办公室\n",
       "1     2  随着片名《教父》的出现，声带上旁白：“我信任美国。”接着，身穿黑色西服、年约六十、神情紧张的...\n",
       "2     3  波拿塞那：我在美国成了家立了业。（画面后景逐渐出现）我把女儿以美国方式培养成人。我给她自由，...\n",
       "3     4  此人此时是在“教父”堂科列奥（注1）的办公室内，百叶窗放下了，房间中暗沉沉的。墙上映着百叶窗...\n",
       "4     5  堂科列奥：波拿塞那，我们是多年的老相识了，可这还是你第一次来求助于我。你最后一次请我上你家去..."
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以数据导入正确，格式也正确，为了便于R读取处理，将这个df存为csv文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但是在网上找了很多，网上大部分都是情感分析，几乎没有针对文本的情绪分析，针对面部表情的情绪分析倒是很多，有些虽然翻译成情绪分析，但是其英语还是sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 权利的游戏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先照猫画虎再说,稍微看了下R，首先有个R基础安装包（80多M），然后有个集成开发环境RStudio（85M），所以安在台式机上了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为是网页全选复制，所以除了正文外，开头部分和结尾部分都有些非正文文本，需要处理掉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Game-of-thrones.txt',encoding='utf8') as f:\n",
    "    content=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "content=content.split('Opening Credits]')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "content=content.split('[End Credits')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "去除开头和结尾的非正文文本之后，接下来去除空行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex=r'^$\\n'\n",
    "subst=\"\"\n",
    "content=re.sub(regex,subst,content,0, re.MULTILINE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面的语句，如果不加上 ,0, re.MULTILINE 这两个参数，也无法完成去除空行的效果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ flags，匹配模式，可以使用按位或‘|‘表示同时生效，也可以在正则表达式中指定。\n",
    "+ re.I忽略大小写\n",
    "+ re.L表示特殊字符集\\w,\\W,\\b,\\B,\\s,\\S\n",
    "+ re.M表示多行模式\n",
    "+ re.S ‘.’包括换行符在内的任意字符\n",
    "+ re.U表示特殊字符集\\w,\\W,\\b,\\B,\\d,\\D,\\s,\\D\n",
    "\n",
    "发现除了换行符之外，还有一些分隔符，虚线表示的，也进行删除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex=r'^- +$\\n'\n",
    "subst=\"\"\n",
    "content=re.sub(regex,subst,content,0, re.MULTILINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines=content.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "478"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['line']=range(1,479)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['text']=lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[First scene shows the location of Casterly Ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>CATELYN: Are you sure about this?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ROBB: No.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>CATELYN: It's dangerous.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[ROBB nods in agreement]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   line                                               text\n",
       "0     1  [First scene shows the location of Casterly Ro...\n",
       "1     2                  CATELYN: Are you sure about this?\n",
       "2     3                                          ROBB: No.\n",
       "3     4                           CATELYN: It's dangerous.\n",
       "4     5                           [ROBB nods in agreement]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "教程那个人用的是mac，所以有框框，像真的数据表一样，好像还是人家的好看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R安装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后到台式机上，试试R\n",
    "\n",
    "+ 安好基础包和集成开发环境后，按照教程上的，先创建一个R notebook，首先会提示让你进行包的安装，然后安装，类似Python\n",
    "+ 安装好之后，会有一段文字，这个叫R markdown语法，和这个的很像，\n",
    "+ 也是一行一行执行的，但是需要选中，不是说光标停留在哪行就执行哪行，而是要选中再执行，才有效\n",
    "+ R语言可以直接在执行环境里进行安装包，和python一样，安了之后需要导入才可以使用\n",
    "    + install.packages(\"dplyr\")\n",
    "    + install.packages(\"tidytext\")\n",
    "    + install.packages(\"tidyr\")\n",
    "    + install.packages(\"ggplot2\")\n",
    "+ 各种执行信息显示在左下角的Console中，数据显示在右边的Script中（前提是用数据，才会显示出Script这个窗口）\n",
    "+ 导入dplyr包时，会显示很多红色信息，但是这不是错误，注意，不是bug，是自动显示的\n",
    "    + 执行library语句调用这些包。\n",
    "    + library(dplyr)\n",
    "    + library(tidytext)\n",
    "    + library(tidyr)\n",
    "    + library(ggplot2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分词"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在R里面，可以采用Tidy Text方式来做。执行的语句是unnest_token，我们把原先的句子拆分成为单词。\n",
    "\n",
    "+ tidy_script <- script %>%\n",
    "  + unnest_tokens(word, text)\n",
    "+ head(tidy_script)\n",
    "\n",
    "所以这里得到分词后的结果是tidy_script\n",
    "\n",
    "\n",
    "+  line     word\n",
    "+ 1      1    first\n",
    "+ 1.1    1    scene\n",
    "+ 1.2    1    shows\n",
    "+ 1.3    1      the\n",
    "+ 1.4    1 location\n",
    "+ 1.5    1       of\n",
    "\n",
    "这里原先的行号依然被保留。我们可以看到每一个词来自于哪一行，这有利于下面我们对行甚至段落单位进行分析。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 找出每个单词的情绪"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "调用加拿大国家研究委员会发布的情绪词典。这个词典在tidytext包里面内置了，就叫做nrc\n",
    "\n",
    "+ tidy_script %>%\n",
    "  + inner_join(get_sentiments(\"nrc\")) %>%\n",
    "  + arrange(line) %>%\n",
    "  + head(10)\n",
    "\n",
    "很明显，这里做了一个等值连接，只是把分词后的结果和NRC表做了内连接，把共同含有的单词找出来了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| |line|word|sentiment|\n",
    "|:-|:-|\n",
    "| 1 |    1|         rock|     positive|\n",
    "| 2 |    1|    ancestral   |     trust|\n",
    "| 3 |    1|        giant |        fear|\n",
    "| 4 |    1| representing| anticipation|\n",
    "| 5 |    1|        stark|     negative|\n",
    "| 6 |    1|        stark |       trust|\n",
    "| 7 |    1|        stark  |   negative|\n",
    "| 8 |    1|        stark  |      trust|\n",
    "| 9 |    4|    dangerous    |     fear|\n",
    "|10 |    4|    dangerous    | negative|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "可以看到，有的词对应某一种情绪属性，有的词同时对应多种情绪属性。注意**nrc包里面不仅有情绪，而且还有情感（正向和负向）**\n",
    "\n",
    "这个结果可以在data.csv文件中找到对应的单词，但是很明显，也没有识别出人名，Stark是僵硬的意思，所以这里给出了负面\n",
    "+ 前8个单词在第一行文本中，第一行中有两个stark,stark这个单词有情绪，trust，也有情感，negative\n",
    "+ 教程里最后的词是dangerous，我的是father(100行)和horse（101行），dangerous在第4行，"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|id|name|\n",
    "|:-|:-|\n",
    "|1|A1|\n",
    "|2|A2|\n",
    "|3|A3|\n",
    "Markdown创建表格"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 每行（句）多少个情感词"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对单词的情绪已经清楚了。下面我们来综合判断每一行的不同情感分别含有几个词。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    tidy_script %>%\n",
    "      inner_join(get_sentiments(\"nrc\")) %>%\n",
    "      count(line, sentiment) %>%\n",
    "      arrange(line) %>%\n",
    "      head(10)\n",
    "Markdown每行缩进四个空格，就是代码块格式了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果我们以1行为单位分析情感变化，粒度过细。鉴于整个剧本包含了几百行文字，我们以5行作为一个基础单位，来进行分析。\n",
    "\n",
    "这里我们使用index来把原先的行号处理一下，分成段落。%/%代表整除符号，这样0-4行就成为了第一段落，5-9行成为第二段落，以此类推。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但是这里报错了，即便是Stack Overflow上的答案，也看不懂了，这篇教程就到这吧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
